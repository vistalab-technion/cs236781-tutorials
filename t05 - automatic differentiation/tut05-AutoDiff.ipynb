{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c67fd4d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Automatic Differentiation\n",
    "## Introduction\n",
    "\n",
    "In this tutorial, we will cover:\n",
    "\n",
    "| Motivation<br>Computational graph<br>Propagating derivatives: forward and reverse AD<br>Generalizing the computational graph<br>The backpropagation algorithm<br>Custom automatic differentiation with PyTorch | <img src=\"https://miro.medium.com/v2/resize:fit:1400/1*NzyxsrkiLjjyjiIuCf123w.png\" alt=\"Image\" style=\"width: 50%;\"> |\n",
    "|:---:|---|\n",
    "\n",
    "\n",
    "\n",
    "* Jacobians and Hessians with AD and PyTorch (Bonus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff910e96",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import time \n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f3c63c5",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 14\n",
    "data_dir = os.path.expanduser('~/.pytorch-datasets')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab958cb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Motivation\n",
    "\n",
    "- In the last tutorial, we applied **first-order algorithms** to perform optimization.\n",
    "- However, we haven't seen how to actually compute the gradients needed to apply them.\n",
    "- Let $f: \\mathbb{R}^d \\rightarrow \\mathbb{R}$. Suppose we want to compute its gradient at some point: $x^{(0)} \\in \\mathbb{R}^d$.\n",
    "- Idea: use numerical differentiation:\n",
    "    - Forward difference:\n",
    "    $$ \\left. \\frac{\\partial f}{\\partial x_i} \\right \\vert_{x=x^{(0)}} \\approx \\frac{f(x^{(0)}_1,...,x_i^{(0)}+h,...,x^{(0)}_d)-f(x^{(0)})}{h} $$\n",
    "        - Requires $d+1$ forward passes.\n",
    "    - Central difference: \n",
    "        $$ \\left. \\frac{\\partial f}{\\partial x_i} \\right \\vert_{x=x^{(0)}} \\approx \\frac{f(x^{(0)}_1,...,x_i^{(0)}+h,...,x^{(0)}_d)-f(x^{(0)}_1,...,x_i^{(0)}-h,...,x^{(0)}_d)}{2h} $$\n",
    "        - Requires $2d$ forward passes.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Numerical_differentiation\n",
    "\n",
    "* Problems?\n",
    "    + Inexact.\n",
    "    + **Very expensive when the dimension is high!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181f9bc6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Motivating example\n",
    "\n",
    "- Let $f(x) = f_n \\circ f_{n-1} \\circ ... \\circ f_1$ where $f_i: \\mathbb{R} \\rightarrow \\mathbb{R}$ are functions that are easy to evaluate and differentiate.\n",
    "    - More precisely, given $x=a$ we can compute $f_i(a)$ and $f_i'(a)$ in $\\mathcal{O}(1)$.\n",
    "    - Such function can be $x^c, sin(x), cos(x), exp(x)$ etc...\n",
    "- Given $a$, how can we efficiently compute $f'(a)$?\n",
    "- Using the chain rule, the derivative is given by:\n",
    "$$ f'(a) = f_n'(f_{n-1}(f_{n-2}(...f_1(a))) \\cdot ... \\cdot f_2'(f_1(a)) \\cdot f_1'(a) $$\n",
    "- Naive algorithm:\n",
    "    - Consider each term independently - $\\mathcal{O}(n^2)$.\n",
    "- Better approach (Dynamic Programming):\n",
    "    - Let $F_j(x) := (f_j \\circ ... \\circ f_1)(x)$.\n",
    "    - Compute and store $F_j(a)$ for each $1 \\leq j \\leq n-1$.\n",
    "    - Afterwards, use the stored results to compute each term in the derivative in $\\mathcal{O}(1)$.\n",
    "    - Totally, $\\mathcal{O}(n)$!\n",
    "    \n",
    "* Can we generalize what happend here?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ee365b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computational graph\n",
    "\n",
    "- The above computation can be viewed as a directed graph $G=(V,E)$, called a **computational graph**.\n",
    "    \n",
    "- In general, a computational graph is a directed acyclic graph (DAG) $G=(V,E)$.\n",
    "- Each node has a:\n",
    "    - Type (<span style=\"color:blue\">input_variable</span>\n",
    "/<span style=\"color:orange\">input_constant</span>/`intermediate`/<span style=\"color:green\">output</span>).\n",
    "        - Type(v) is `input`(either variable or constant) iff $deg_{in}(v)=0$.\n",
    "            - Variable if requires gradient computation (model parameters etc...)\n",
    "                - Blue node.\n",
    "            - Constant otherwise (hyper-parameters, $x$ in NN architectures, etc...)\n",
    "                - Orange node.\n",
    "            - In code, determine by setting ```.requires_grad``` field.\n",
    "            - By default, False for tensors, True for built-in modules' parameters.\n",
    "        - Type(v) is `output` iff $deg_{out}(v)=0$.\n",
    "            - Green node.\n",
    "        - Otherwise, `intermediate`.\n",
    "            - Grey node.\n",
    "    - Three fields: function (```.fn```), value (```.val```) and gradient (```.grad```)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464764d6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In our case:\n",
    "<center><img src=\"imgs/chain.png\"/ height=70% width=70%> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602e90df",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- For each node we associate a **value** (in our case - $F_j(a)$) which is computed via a process we name **forward pass**.\n",
    "    - The values of the nodes are computed in a **topological order**.\n",
    "    - Initialize: $v_0.val \\leftarrow a$\n",
    "    - Update: $v_{j+1}.val \\leftarrow v_{j+1}.fn(v_j.val)$\n",
    "\n",
    "<center><img src=\"imgs/chain_forward.png\"/ height=70% width=70%> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216e2e38",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Propagating derivatives: forward and reverse AD\n",
    "\n",
    "- The derivative $\\frac{d v_n}{d v_0}$ can be now computed by two DP approaches.\n",
    "- Denote $D_{i,j} := \\frac{dv_i}{dv_j}(F_j(a))$.\n",
    "- First approach: by propagating the gradient from the input to the output.\n",
    "    - Invariant: $v_j.grad = \\frac{d v_j}{d v_0}(a)$.\n",
    "    - Initialize: $v_0.grad \\leftarrow 1$\n",
    "    - Update grads in a **topological order**: $v_{j+1}.grad \\leftarrow v_{j+1}.fn.derivative(v_j.val) \\cdot v_j.grad$.\n",
    "- This process is called **forward mode AD**!\n",
    "        \n",
    "<center><img src=\"imgs/chain_forwardAD.png\"/ height=70% width=70%> </center>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d246a217",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Second approach: by propagating the gradient from the output to the input.\n",
    "     - Invariant: $v_j.grad = \\frac{d v_n}{d v_j}(F_j(a))$.\n",
    "     - Initialize: $v_n.grad \\leftarrow 1$\n",
    "     - Update grads in a **reverse topological order**:\n",
    "     $v_{j-1}.grad \\leftarrow v_j.fn.derivative(v_{j-1}.val) \\cdot v_j.grad$.   \n",
    "- This process is called **reverse mode AD**!\n",
    "\n",
    "<center><img src=\"imgs/chain_reverseAD.png\"/ height=70% width=70%> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c848cf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Generalizing the computational graph\n",
    "\n",
    "- Generalization: multiple input nodes and output nodes\n",
    "    - Forward mode AD: each node has to store the gradient w.r.t all the **input** nodes.\n",
    "    - Reverse mode AD: each node has to store the gradient of all the **output** nodes w.r.t the nodes.\n",
    "- Q: which mode should be used for computing gradients?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c032994",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A: reverse! requires saving only one ```.grad``` per each parameter! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0beb42",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Generalization: intermediate nodes with multiple inputs and outputs!\n",
    "    - Examples:\n",
    "        - Addition/multiplication blocks with $k$ inputs\n",
    "        - Vector addition/dot product\n",
    "        - Vector elementwise operations\n",
    "        - Matrix multiplication\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2c02f9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Denote by $\\mathcal{N}_{in}(v)$ all the nodes incoming to $v$ and by $\\mathcal{N}_{out}(v)$ all the nodes outgoing of $v$.\n",
    "* When computing values (forward pass):\n",
    "    - Update rule becomes: $v.val \\leftarrow f_v(\\mathcal{N}_{in}(v).val)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facafb9b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- When computing gradients:\n",
    "    - Consider partial derivatives for intermediate noeds with multiple inputs.\n",
    "    - Sum the update rule of the ```.grad``` field along inputs (in forward mode) and outputs (in reverse mode).\n",
    "    - Forward mode AD update becomes: $v.grad \\leftarrow \\sum_{u \\in \\mathcal{N}_{in}(v)} \\frac{\\partial f_v}{\\partial u}(\\mathcal{N}_{in}(v).val) \\cdot u.grad$. \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb040a5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Reverse mode AD update becomes: $v.grad \\leftarrow \\sum_{w \\in \\mathcal{N}_{out}(v)} \\frac{\\partial f_w}{\\partial v}(\\mathcal{N}_{in}(w).val) \\cdot w.grad$. \n",
    "    - For each $w \\in \\mathcal{N}_{out}(v)$ note that $\\frac{\\partial f_w}{\\partial v}(\\mathcal{N}_{in}(w).val) \\cdot w.grad$ note that can be precomputed and stored on the edge $e=(v,w)$.\n",
    "    - Then, to compute $v.grad$, just sum the outgoing edges.\n",
    "    - Compute $\\frac{\\partial f_v}{\\partial u}(\\mathcal{N}_{in}(v).val) \\cdot v.grad$ for each $u \\in \\mathcal{N}_{in}(v)$ and stoe it on the edge $e=(u,v)$ to be used by the ingoing nodes.\n",
    "        \n",
    "<center><img src=\"imgs/backprop-modular.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037f523f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "- Consider the function $f(x,y)=sin(xy)+e^{xy}$. \n",
    "- Compute its gradient at $(x,y)=(1,2)$ using:\n",
    "    - Manual differentiation.\n",
    "    - Forward mode AD. \n",
    "    - Reverse mode AD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6e7264",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Manual:\n",
    "$$ \\frac{\\partial}{\\partial x} f(x,y) = y cos(xy) + y e^{xy} \\rightarrow \\frac{\\partial}{\\partial x} f(1,2) = 2cos(2)+2e^2 $$\n",
    "$$ \\frac{\\partial}{\\partial y} f(x,y) = x cos(xy) + x e^{xy} \\rightarrow \\frac{\\partial}{\\partial y} f(1,2) = cos(2)+e^2 $$\n",
    "Hence the gradient at $(1,2)$ is $(2cos(2)+2e^2,cos(2)+e^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaf0c3a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- For the automatic modes, let's build a computational graph for $f$!\n",
    "    - Make sure that the nodes are topologically.\n",
    "\n",
    "    <center><img src=\"imgs/example_graph.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0a300b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Let's perform a forward pass!\n",
    "    - Begin by initializing the ```.val``` fields of the input nodes.\n",
    "    - Process the nodes by their order.\n",
    "    - Update the ```.val``` field by applying the function in the ```.fn``` field to the incoming nodes.\n",
    "        \n",
    "     <center><img src=\"imgs/example_forward.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96db855",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- For the forward AD let's perform a forward gradient propagation!\n",
    "    - Since there are two inputs, should repeat the process twice.\n",
    "    - Begin by initializing the ``` .grad ``` field of the revlevant **input** node to $1$ and the ```.grad ``` field of the other **input** nodes to $0$.\n",
    "    - Process the nodes in their order\n",
    "        - Compute the partial derivatives of the function in the node w.r.t their inputs.\n",
    "        - For each input - multiply the computed derivative by the ```.grad``` field of the corresponding input.\n",
    "        - Sum the \"messages\" from the input nodes to update ```.grad``` field of the node.\n",
    "    - We will demonstrate the process for $x$.\n",
    "        - The process for $y$ is left as an exercise to the reader.\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c30dcf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"imgs/example_forwardAD.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88009363",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- For the reverse AD let's perform a reverse gradient propagation!\n",
    "    - Since there is only one output in our case, the process is done only once!\n",
    "    - Begin by:\n",
    "        - Initializing the ``` .grad ``` field of the revlevant **output** nodes to $1$ and the ```.grad ``` field of the other **output** nodes to $0$.\n",
    "        - Computing the partial derivatives of the function in the output nodes w.r.t their inputs\n",
    "        - \"Sending\" the derivatives using the corresponding edges.\n",
    "    - Process the nodes in a **reversed order**:\n",
    "        - Sum the \"messages\" in the output edges to update the ```.grad``` field of the node.\n",
    "        - Compute the partial derivatives of the function in the node w.r.t their inputs.\n",
    "        - \"send\" the derivatives using the corresponding edges.\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06892c86",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"imgs/example_reverseAD.png\" width=\"700\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa838564",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The backpropagation algorithm\n",
    "\n",
    "- Essentially forward pass + reverse mode AD in the computational graph generated by a neural network.\n",
    "- For this exact reason the ```.backward()``` method supports only **scalar outputs** (otherwise, should save gradient for each output...)\n",
    "- PyTorch automatically builds computational graphs when at least one variable that requires gradient is created.\n",
    "%- We will see later on an application for the forward mode AD..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b28569",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Custom automatic differentiation with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b491d7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We'll now learn how to extend PyTorch's `autograd` by defining our own custom nodes in the computation graph.\n",
    "\n",
    "Lets first introduce a cousin of ReLU, the Exponential-Linear Unit (ELU) activation function:\n",
    "\n",
    "$$\n",
    "f(z) =\n",
    "\\begin{cases}\n",
    "z, & z > 0\\\\\n",
    "\\alpha \\left(e^{z}-1\\right) & z \\leq 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2527cd90",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We'll pretend PyTorch does not include this activation function and implement a custom version ourselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df9cae6e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torchviz\n",
    "\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b61896",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, we'll implement just the actual computation as a standalone function so that we can reuse it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0136fc37",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def elu_forward(z: Tensor, alpha: float):\n",
    "    elu_positive = z\n",
    "    elu_negative = alpha * (torch.exp(z) - 1)\n",
    "    elu_output = torch.where(z>0, elu_positive, elu_negative)\n",
    "    return elu_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e863b1e0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A quick visualization to see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fca53a6c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = torch.linspace(-5, 5, steps=1000)\n",
    "plt.plot(z.numpy(), torch.relu(z).numpy(), label='ReLU(z)', linewidth=5);\n",
    "plt.plot(z.numpy(), elu_forward(z, alpha=.5).numpy(), label='ELU(z)', linewidth=2); plt.legend(); plt.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c2b96c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now we'll wrap it as an `nn.Module` so that we can use it as a layer in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d3aa4eb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class ELU(torch.nn.Module):\n",
    "    \"\"\" ELU Activation layer \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, z: Tensor):\n",
    "        return elu_forward(z, self.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce315a0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "And as usual, we can look at the resulting computation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc4bc58a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"140pt\" height=\"380pt\"\n",
       " viewBox=\"0.00 0.00 140.00 380.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 376)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-376 136,-376 136,4 -4,4\"/>\n",
       "<!-- 5714084224 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>5714084224</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"77.5,-31 23.5,-31 23.5,0 77.5,0 77.5,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (6)</text>\n",
       "</g>\n",
       "<!-- 5713775968 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5713775968</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-86 0,-86 0,-67 101,-67 101,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">WhereBackward0</text>\n",
       "</g>\n",
       "<!-- 5713775968&#45;&gt;5714084224 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5713775968&#45;&gt;5714084224</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-66.79C50.5,-60.07 50.5,-50.4 50.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-41.19 50.5,-31.19 47,-41.19 54,-41.19\"/>\n",
       "</g>\n",
       "<!-- 5713774288 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>5713774288</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-306 0,-306 0,-287 101,-287 101,-306\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5713774288&#45;&gt;5713775968 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>5713774288&#45;&gt;5713775968</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M46.13,-286.91C41.94,-278.14 35.9,-264.01 33.5,-251 23.1,-194.62 23.1,-178.38 33.5,-122 35.17,-112.95 38.6,-103.36 41.94,-95.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"45.23,-96.65 46.13,-86.09 38.84,-93.78 45.23,-96.65\"/>\n",
       "</g>\n",
       "<!-- 5714077296 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5714077296</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"132,-251 43,-251 43,-232 132,-232 132,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">ExpBackward0</text>\n",
       "</g>\n",
       "<!-- 5713774288&#45;&gt;5714077296 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5713774288&#45;&gt;5714077296</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M56.61,-286.75C61.78,-279.34 69.35,-268.5 75.69,-259.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78.65,-261.29 81.5,-251.09 72.91,-257.29 78.65,-261.29\"/>\n",
       "</g>\n",
       "<!-- 5714083984 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>5714083984</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-372 23.5,-372 23.5,-342 77.5,-342 77.5,-372\"/>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-360\" font-family=\"monospace\" font-size=\"10.00\">z</text>\n",
       "<text text-anchor=\"middle\" x=\"50.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\"> (6)</text>\n",
       "</g>\n",
       "<!-- 5714083984&#45;&gt;5713774288 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>5714083984&#45;&gt;5713774288</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M50.5,-341.84C50.5,-334.21 50.5,-324.7 50.5,-316.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"54,-316.27 50.5,-306.27 47,-316.27 54,-316.27\"/>\n",
       "</g>\n",
       "<!-- 5714076912 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>5714076912</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"132,-141 43,-141 43,-122 132,-122 132,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 5714076912&#45;&gt;5713775968 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>5714076912&#45;&gt;5713775968</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M81.39,-121.75C76.22,-114.34 68.65,-103.5 62.31,-94.41\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"65.09,-92.29 56.5,-86.09 59.35,-96.29 65.09,-92.29\"/>\n",
       "</g>\n",
       "<!-- 5714077200 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5714077200</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"132,-196 43,-196 43,-177 132,-177 132,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"87.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 5714077200&#45;&gt;5714076912 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5714077200&#45;&gt;5714076912</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M87.5,-176.75C87.5,-169.8 87.5,-159.85 87.5,-151.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"91,-151.09 87.5,-141.09 84,-151.09 91,-151.09\"/>\n",
       "</g>\n",
       "<!-- 5714077296&#45;&gt;5714077200 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>5714077296&#45;&gt;5714077200</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M87.5,-231.75C87.5,-224.8 87.5,-214.85 87.5,-206.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"91,-206.09 87.5,-196.09 84,-206.09 91,-206.09\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x15483b1f0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elu = ELU(alpha=0.5)\n",
    "z = torch.tensor([-2., -1, 0, 1, 2, 3], requires_grad=True)\n",
    "torchviz.make_dot(elu(z), params=dict(z=z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4d5c04",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can see that the computation graph accurately represents the various basic mathematical operations performed by our `elu_forward` function.\n",
    "\n",
    "But what if we want to define the entire ELU operarion as one node in the graph?\n",
    "This can be useful e.g. for performance reasons or if pytorch can't differentiate through our layer.\n",
    "\n",
    "How can we accomplish this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5106413b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The solution is to use a lower-level PyTorch API, `autograd.Function`\n",
    "which allows us to define a function in terms of both it's forwards pass\n",
    "(the regular output computation), and it's **backward** pass\n",
    "(the gradient w.r.t. all its inputs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54759cd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "From the PyTorch docs:\n",
    "    \n",
    ">Every operation performed on `Tensors`s creates a new `Function` object, that performs the computation, and records that it happened. The history is retained in the form of a DAG of functions, with edges denoting data dependencies (input <- output). Then, when backward is called, the graph is processed in the topological ordering, by calling `backward()` methods of each `Function` object, and passing returned gradients on to next `Function`s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe88e83",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The API of an `autograd.Function` is:\n",
    "\n",
    "```python\n",
    "class MyCustomFunction(autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(context, *inputs: Tensor, **kw):\n",
    "        ...\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(context, *grad_outputs: Tensor) -> Sequence[Tensor]:\n",
    "        ...\n",
    "```\n",
    "\n",
    "1. What do you think `grad_outputs` contains?\n",
    "2. What does `backward()` need to return?\n",
    "3. Why do we need a `context`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba045942",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To implement the ELU as an `autograd.Function`, we'll first calculate the simple analytic derivative of the ELU function:\n",
    "$$\n",
    "\\frac{\\partial f(z)}{\\partial z} = f'(z) = \n",
    "\\begin{cases}\n",
    "1, & z > 0\\\\\n",
    "\\alpha e^{z} & z \\leq 0\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e6dc33",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Next, we need to figure out how to compute the vector-Jacobian product efficiently.\n",
    "Note that for any **elementwise** operation, $\\vec{y}=f(\\vec{x}),\\ f:\\mathbb{R}^n\\rightarrow\\mathbb{R}^n$, we can write the Jacobian as\n",
    "\n",
    "$$\n",
    "\\frac{d \\vec{y}}{d \\vec{x}} = \\pmatrix{\n",
    "\\ddots & \\vdots & \\\\\n",
    "\\cdots & \\frac{\\partial y_i}{ \\partial x_j} & \\cdots \\\\\n",
    "& \\vdots & \\ddots\\\\\n",
    "}\n",
    "=\n",
    "\\pmatrix{\n",
    "f'(x_1) &  &  \\\\\n",
    "  & f'(x_i) &  \\\\\n",
    "& & f'(x_n)\\\\\n",
    "}\n",
    "= Diag\\{{f'(\\vec{x})}\\}\n",
    "$$\n",
    "\n",
    "And it follows that the VJP can be computed simply:\n",
    "$$\n",
    "\\delta \\vec{x} = \\delta{\\vec{y}}\\frac{\\partial \\vec{y}}{\\partial \\vec{x}} = \\delta{\\vec{y}} \\odot f'(\\vec{x}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36154af2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, equipped with the expression for the VJP, we can proceed to implement the `Function` object representing ELU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "170508be",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class ELUFunction(autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, z: Tensor, alpha: float):\n",
    "        elu = elu_forward(z, alpha) # Regular forward pass computation from before\n",
    "        ctx.save_for_backward(z)    # Tensors should be saved using this method\n",
    "        ctx.alpha = alpha           # other properties can be saved like so\n",
    "        return elu\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        z, = ctx.saved_tensors      # Validates that no in-place modifications happened on saved tensors\n",
    "        alpha = ctx.alpha\n",
    "        \n",
    "        # Calculate diagonal of d(elu(z))/dz\n",
    "        grad_positive = torch.ones_like(z)\n",
    "        grad_negative = alpha * torch.exp(z)\n",
    "        \n",
    "        # Note: This is not the full Jacobian, d(elu(z))/dz, it's the diagonal\n",
    "        grad_elu = torch.where(z>0, grad_positive, grad_negative)\n",
    "\n",
    "        # Gradient of the loss w.r.t. our output\n",
    "        _elu = grad_output\n",
    "        \n",
    "        # Calcualte z = d(elu(z))/dz * _elu\n",
    "        # Note: elementwise multiplication equivalant to vector-Jacobian product\n",
    "        z = grad_elu * _elu\n",
    "        return z, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7bdbf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can now use this custom `Function` either directly or as part of a layer.\n",
    "\n",
    "For example, here's an ELU layer using our custom backward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14aefc1e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class ELUCustom(torch.nn.Module):\n",
    "    \"\"\" ELU Layer with a custom backward pass \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, z: Tensor):\n",
    "        # Function.apply() invokesa the forward pass with a new context\n",
    "        # and updates the computation graph of the inputs\n",
    "        return ELUFunction.apply(z, self.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c14ee339",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"164pt\" height=\"215pt\"\n",
       " viewBox=\"0.00 0.00 164.00 215.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 211)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-211 160,-211 160,4 -4,4\"/>\n",
       "<!-- 5714053776 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>5714053776</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"92.5,-31 38.5,-31 38.5,0 92.5,0 92.5,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"65.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (6)</text>\n",
       "</g>\n",
       "<!-- 5714178112 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5714178112</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"131,-86 0,-86 0,-67 131,-67 131,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"65.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">ELUFunctionBackward</text>\n",
       "</g>\n",
       "<!-- 5714178112&#45;&gt;5714053776 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5714178112&#45;&gt;5714053776</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M65.5,-66.79C65.5,-60.07 65.5,-50.4 65.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"69,-41.19 65.5,-31.19 62,-41.19 69,-41.19\"/>\n",
       "</g>\n",
       "<!-- 5714079360 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>5714079360</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"156,-141 55,-141 55,-122 156,-122 156,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"105.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5714079360&#45;&gt;5714178112 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>5714079360&#45;&gt;5714178112</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M98.89,-121.75C93.24,-114.26 84.96,-103.28 78.05,-94.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"80.8,-91.96 71.98,-86.09 75.21,-96.18 80.8,-91.96\"/>\n",
       "</g>\n",
       "<!-- 5353648992 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>5353648992</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"92.5,-207 38.5,-207 38.5,-177 92.5,-177 92.5,-207\"/>\n",
       "<text text-anchor=\"middle\" x=\"65.5\" y=\"-195\" font-family=\"monospace\" font-size=\"10.00\">z</text>\n",
       "<text text-anchor=\"middle\" x=\"65.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (6)</text>\n",
       "</g>\n",
       "<!-- 5353648992&#45;&gt;5714178112 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>5353648992&#45;&gt;5714178112</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.55,-176.86C50.73,-163.01 42.57,-141.23 46.5,-122 48.39,-112.74 52.29,-103.03 56.07,-95.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"59.24,-96.53 60.62,-86.02 52.99,-93.37 59.24,-96.53\"/>\n",
       "</g>\n",
       "<!-- 5353648992&#45;&gt;5714079360 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>5353648992&#45;&gt;5714079360</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M75.18,-176.84C80.75,-168.69 87.79,-158.4 93.68,-149.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"96.75,-151.5 99.51,-141.27 90.97,-147.55 96.75,-151.5\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x15495e8b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elu_custom = ELUCustom(alpha=0.5)\n",
    "z = torch.tensor([-2., -1, 0, 1, 2, 3], requires_grad=True)\n",
    "torchviz.make_dot(elu_custom(z), params=dict(z=z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a494029a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This only tested the forward pass. Let's now put our custom layer in the context of a larger model and see that we can backprop through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc927151",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "  (1): ELUCustom()\n",
       "  (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "  (3): ELUCustom()\n",
       "  (4): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  (5): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elu_mlp = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=512, out_features=1024,bias=False),\n",
    "    ELUCustom(alpha=0.01),\n",
    "    torch.nn.Linear(in_features=1024, out_features=1024),\n",
    "    ELUCustom(alpha=0.01),\n",
    "    torch.nn.Linear(in_features=1024, out_features=10),\n",
    "    torch.nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "elu_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72fefff0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.50.0 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"475pt\" height=\"657pt\"\n",
       " viewBox=\"0.00 0.00 475.00 657.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 653)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-653 471,-653 471,4 -4,4\"/>\n",
       "<!-- 5714086944 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>5714086944</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"306.5,-31 252.5,-31 252.5,0 306.5,0 306.5,-31\"/>\n",
       "<text text-anchor=\"middle\" x=\"279.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 5714127120 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>5714127120</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"327,-86 232,-86 232,-67 327,-67 327,-86\"/>\n",
       "<text text-anchor=\"middle\" x=\"279.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\n",
       "</g>\n",
       "<!-- 5714127120&#45;&gt;5714086944 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>5714127120&#45;&gt;5714086944</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M279.5,-66.79C279.5,-60.07 279.5,-50.4 279.5,-41.34\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"283,-41.19 279.5,-31.19 276,-41.19 283,-41.19\"/>\n",
       "</g>\n",
       "<!-- 5714125968 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>5714125968</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"336,-141 223,-141 223,-122 336,-122 336,-141\"/>\n",
       "<text text-anchor=\"middle\" x=\"279.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">SoftmaxBackward0</text>\n",
       "</g>\n",
       "<!-- 5714125968&#45;&gt;5714127120 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>5714125968&#45;&gt;5714127120</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M279.5,-121.75C279.5,-114.8 279.5,-104.85 279.5,-96.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"283,-96.09 279.5,-86.09 276,-96.09 283,-96.09\"/>\n",
       "</g>\n",
       "<!-- 5714127600 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>5714127600</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"330,-196 229,-196 229,-177 330,-177 330,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"279.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 5714127600&#45;&gt;5714125968 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>5714127600&#45;&gt;5714125968</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M279.5,-176.75C279.5,-169.8 279.5,-159.85 279.5,-151.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"283,-151.09 279.5,-141.09 276,-151.09 283,-151.09\"/>\n",
       "</g>\n",
       "<!-- 5714128272 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>5714128272</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"181,-251 80,-251 80,-232 181,-232 181,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5714128272&#45;&gt;5714127600 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>5714128272&#45;&gt;5714127600</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M154.44,-231.98C179.06,-223.23 217.62,-209.51 245.42,-199.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"246.88,-202.82 255.12,-196.17 244.53,-196.22 246.88,-202.82\"/>\n",
       "</g>\n",
       "<!-- 5714121328 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5714121328</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"127.5,-317.5 73.5,-317.5 73.5,-287.5 127.5,-287.5 127.5,-317.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"100.5\" y=\"-305.5\" font-family=\"monospace\" font-size=\"10.00\">4.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"100.5\" y=\"-294.5\" font-family=\"monospace\" font-size=\"10.00\"> (10)</text>\n",
       "</g>\n",
       "<!-- 5714121328&#45;&gt;5714128272 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5714121328&#45;&gt;5714128272</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M107.76,-287.22C111.85,-279.18 116.99,-269.06 121.36,-260.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"124.59,-261.84 126,-251.34 118.35,-258.67 124.59,-261.84\"/>\n",
       "</g>\n",
       "<!-- 5712547408 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5712547408</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"345,-251 214,-251 214,-232 345,-232 345,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"279.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">ELUFunctionBackward</text>\n",
       "</g>\n",
       "<!-- 5712547408&#45;&gt;5714127600 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>5712547408&#45;&gt;5714127600</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M279.5,-231.75C279.5,-224.8 279.5,-214.85 279.5,-206.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"283,-206.09 279.5,-196.09 276,-206.09 283,-206.09\"/>\n",
       "</g>\n",
       "<!-- 5714126832 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>5714126832</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"247,-312 146,-312 146,-293 247,-293 247,-312\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.5\" y=\"-300\" font-family=\"monospace\" font-size=\"10.00\">AddmmBackward0</text>\n",
       "</g>\n",
       "<!-- 5714126832&#45;&gt;5712547408 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5714126832&#45;&gt;5712547408</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M208.75,-292.79C221.94,-283.42 243.16,-268.33 258.92,-257.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"261.35,-259.7 267.47,-251.05 257.29,-253.99 261.35,-259.7\"/>\n",
       "</g>\n",
       "<!-- 5714128032 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>5714128032</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"102,-378.5 1,-378.5 1,-359.5 102,-359.5 102,-378.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"51.5\" y=\"-366.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5714128032&#45;&gt;5714126832 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5714128032&#45;&gt;5714126832</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M70.75,-359.43C95.56,-348.4 138.91,-329.12 167.66,-316.33\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"169.45,-319.36 177.17,-312.1 166.61,-312.97 169.45,-319.36\"/>\n",
       "</g>\n",
       "<!-- 5712878864 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>5712878864</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"59,-450.5 0,-450.5 0,-420.5 59,-420.5 59,-450.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"29.5\" y=\"-438.5\" font-family=\"monospace\" font-size=\"10.00\">2.bias</text>\n",
       "<text text-anchor=\"middle\" x=\"29.5\" y=\"-427.5\" font-family=\"monospace\" font-size=\"10.00\"> (1024)</text>\n",
       "</g>\n",
       "<!-- 5712878864&#45;&gt;5714128032 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>5712878864&#45;&gt;5714128032</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M34.38,-420.19C37.61,-410.71 41.88,-398.21 45.34,-388.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"48.67,-389.13 48.59,-378.54 42.05,-386.87 48.67,-389.13\"/>\n",
       "</g>\n",
       "<!-- 5712546448 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>5712546448</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"262,-378.5 131,-378.5 131,-359.5 262,-359.5 262,-378.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"196.5\" y=\"-366.5\" font-family=\"monospace\" font-size=\"10.00\">ELUFunctionBackward</text>\n",
       "</g>\n",
       "<!-- 5712546448&#45;&gt;5714126832 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>5712546448&#45;&gt;5714126832</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M196.5,-359.3C196.5,-349.82 196.5,-334.38 196.5,-322.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"200,-322.06 196.5,-312.06 193,-322.06 200,-322.06\"/>\n",
       "</g>\n",
       "<!-- 5714125680 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>5714125680</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"160,-445 77,-445 77,-426 160,-426 160,-445\"/>\n",
       "<text text-anchor=\"middle\" x=\"118.5\" y=\"-433\" font-family=\"monospace\" font-size=\"10.00\">MmBackward0</text>\n",
       "</g>\n",
       "<!-- 5714125680&#45;&gt;5712546448 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>5714125680&#45;&gt;5712546448</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M129.02,-425.8C141.65,-415.36 163.04,-397.66 178.36,-385\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"180.67,-387.63 186.15,-378.56 176.21,-382.24 180.67,-387.63\"/>\n",
       "</g>\n",
       "<!-- 5714125776 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>5714125776</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"116,-511.5 15,-511.5 15,-492.5 116,-492.5 116,-511.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"65.5\" y=\"-499.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5714125776&#45;&gt;5714125680 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>5714125776&#45;&gt;5714125680</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M72.65,-492.3C80.91,-482.24 94.7,-465.47 105,-452.93\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"107.82,-455.01 111.47,-445.06 102.41,-450.57 107.82,-455.01\"/>\n",
       "</g>\n",
       "<!-- 5360693632 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>5360693632</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"104,-583 27,-583 27,-553 104,-553 104,-583\"/>\n",
       "<text text-anchor=\"middle\" x=\"65.5\" y=\"-571\" font-family=\"monospace\" font-size=\"10.00\">x</text>\n",
       "<text text-anchor=\"middle\" x=\"65.5\" y=\"-560\" font-family=\"monospace\" font-size=\"10.00\"> (10, 512)</text>\n",
       "</g>\n",
       "<!-- 5360693632&#45;&gt;5714125776 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>5360693632&#45;&gt;5714125776</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M65.5,-552.8C65.5,-543.7 65.5,-531.79 65.5,-521.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"69,-521.84 65.5,-511.84 62,-521.84 69,-521.84\"/>\n",
       "</g>\n",
       "<!-- 5714125632 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>5714125632</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"211,-511.5 134,-511.5 134,-492.5 211,-492.5 211,-511.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.5\" y=\"-499.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 5714125632&#45;&gt;5714125680 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>5714125632&#45;&gt;5714125680</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M165.22,-492.3C156.8,-482.24 142.75,-465.47 132.25,-452.93\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"134.77,-450.48 125.67,-445.06 129.4,-454.98 134.77,-450.48\"/>\n",
       "</g>\n",
       "<!-- 5714125440 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>5714125440</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"223,-577.5 122,-577.5 122,-558.5 223,-558.5 223,-577.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.5\" y=\"-565.5\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5714125440&#45;&gt;5714125632 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>5714125440&#45;&gt;5714125632</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M172.5,-558.37C172.5,-549.16 172.5,-534.29 172.5,-522.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"176,-521.91 172.5,-511.91 169,-521.91 176,-521.91\"/>\n",
       "</g>\n",
       "<!-- 5714123568 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>5714123568</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"217,-649 128,-649 128,-619 217,-619 217,-649\"/>\n",
       "<text text-anchor=\"middle\" x=\"172.5\" y=\"-637\" font-family=\"monospace\" font-size=\"10.00\">0.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"172.5\" y=\"-626\" font-family=\"monospace\" font-size=\"10.00\"> (1024, 512)</text>\n",
       "</g>\n",
       "<!-- 5714123568&#45;&gt;5714125440 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>5714123568&#45;&gt;5714125440</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M172.5,-618.8C172.5,-609.7 172.5,-597.79 172.5,-587.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"176,-587.84 172.5,-577.84 169,-587.84 176,-587.84\"/>\n",
       "</g>\n",
       "<!-- 5714121888 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>5714121888</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"261,-451 178,-451 178,-420 261,-420 261,-451\"/>\n",
       "<text text-anchor=\"middle\" x=\"219.5\" y=\"-427\" font-family=\"monospace\" font-size=\"10.00\"> (10, 1024)</text>\n",
       "</g>\n",
       "<!-- 5714121888&#45;&gt;5712546448 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>5714121888&#45;&gt;5712546448</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M214.28,-419.86C210.97,-410.58 206.66,-398.5 203.11,-388.55\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"206.3,-387.07 199.65,-378.82 199.71,-389.42 206.3,-387.07\"/>\n",
       "</g>\n",
       "<!-- 5714127984 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>5714127984</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"357,-378.5 280,-378.5 280,-359.5 357,-359.5 357,-378.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"318.5\" y=\"-366.5\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 5714127984&#45;&gt;5714126832 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>5714127984&#45;&gt;5714126832</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M302.3,-359.43C281.7,-348.54 245.91,-329.62 221.72,-316.84\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"223.24,-313.68 212.77,-312.1 219.97,-319.87 223.24,-313.68\"/>\n",
       "</g>\n",
       "<!-- 5714128464 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>5714128464</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"380,-445 279,-445 279,-426 380,-426 380,-445\"/>\n",
       "<text text-anchor=\"middle\" x=\"329.5\" y=\"-433\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5714128464&#45;&gt;5714127984 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>5714128464&#45;&gt;5714127984</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M328.02,-425.8C326.4,-416.32 323.77,-400.88 321.68,-388.64\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"325.09,-387.83 319.96,-378.56 318.19,-389.01 325.09,-387.83\"/>\n",
       "</g>\n",
       "<!-- 5363147376 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>5363147376</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"377,-517 282,-517 282,-487 377,-487 377,-517\"/>\n",
       "<text text-anchor=\"middle\" x=\"329.5\" y=\"-505\" font-family=\"monospace\" font-size=\"10.00\">2.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"329.5\" y=\"-494\" font-family=\"monospace\" font-size=\"10.00\"> (1024, 1024)</text>\n",
       "</g>\n",
       "<!-- 5363147376&#45;&gt;5714128464 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>5363147376&#45;&gt;5714128464</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M329.5,-486.69C329.5,-477.41 329.5,-465.23 329.5,-455.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"333,-455.04 329.5,-445.04 326,-455.04 333,-455.04\"/>\n",
       "</g>\n",
       "<!-- 5714121808 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>5714121808</title>\n",
       "<polygon fill=\"orange\" stroke=\"black\" points=\"348,-318 265,-318 265,-287 348,-287 348,-318\"/>\n",
       "<text text-anchor=\"middle\" x=\"306.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\"> (10, 1024)</text>\n",
       "</g>\n",
       "<!-- 5714121808&#45;&gt;5712547408 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>5714121808&#45;&gt;5712547408</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M299.83,-286.92C296.18,-278.96 291.64,-269.04 287.78,-260.59\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"290.85,-258.89 283.5,-251.25 284.48,-261.8 290.85,-258.89\"/>\n",
       "</g>\n",
       "<!-- 5714127936 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>5714127936</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"447,-251 370,-251 370,-232 447,-232 447,-251\"/>\n",
       "<text text-anchor=\"middle\" x=\"408.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">TBackward0</text>\n",
       "</g>\n",
       "<!-- 5714127936&#45;&gt;5714127600 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>5714127936&#45;&gt;5714127600</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M387.77,-231.98C366.74,-223.34 333.95,-209.87 309.96,-200.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"311.18,-196.73 300.6,-196.17 308.52,-203.21 311.18,-196.73\"/>\n",
       "</g>\n",
       "<!-- 5714125344 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>5714125344</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"467,-312 366,-312 366,-293 467,-293 467,-312\"/>\n",
       "<text text-anchor=\"middle\" x=\"416.5\" y=\"-300\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 5714125344&#45;&gt;5714127936 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>5714125344&#45;&gt;5714127936</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M415.32,-292.79C414.2,-284.52 412.47,-271.79 411.04,-261.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"414.5,-260.68 409.69,-251.24 407.56,-261.62 414.5,-260.68\"/>\n",
       "</g>\n",
       "<!-- 5359996016 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>5359996016</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"458,-384 375,-384 375,-354 458,-354 458,-384\"/>\n",
       "<text text-anchor=\"middle\" x=\"416.5\" y=\"-372\" font-family=\"monospace\" font-size=\"10.00\">4.weight</text>\n",
       "<text text-anchor=\"middle\" x=\"416.5\" y=\"-361\" font-family=\"monospace\" font-size=\"10.00\"> (10, 1024)</text>\n",
       "</g>\n",
       "<!-- 5359996016&#45;&gt;5714125344 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>5359996016&#45;&gt;5714125344</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M416.5,-353.69C416.5,-344.41 416.5,-332.23 416.5,-322.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"420,-322.04 416.5,-312.04 413,-322.04 420,-322.04\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x15496ac10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(10, 512, requires_grad=True)\n",
    "torchviz.make_dot(elu_mlp(x).mean(), params=dict(list(elu_mlp.named_parameters()) + [('x', x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6cab0a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's run the backward pass and make sure we have gradients on all parameter tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e3f2f0e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight 2.0129235167587467e-07\n",
      "2.weight 3.194509758941422e-07\n",
      "2.bias 2.9578931304286016e-08\n",
      "4.weight 3.4803895232471405e-07\n",
      "4.bias 7.567952309273096e-08\n"
     ]
    }
   ],
   "source": [
    "l = torch.sum(elu_mlp(torch.randn(10, 512, requires_grad=True)))\n",
    "l.backward()\n",
    "\n",
    "for name, param in elu_mlp.named_parameters():\n",
    "    print(f\"{name} {torch.norm(param.grad).item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33b4157",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Jacobians and Hessians with AD and PyTorch (Bonus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf639e1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* In general, Jacobians and Hessains become very large for modern neural network architectures.\n",
    "* Despite their **immense** computation and memory burdens, PyTorch still provides an API for their explicit computation:\n",
    "    https://pytorch.org/functorch/stable/notebooks/jacobians_hessians.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078933e9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- However, in many cases we don't really need to compute the Jacobian or the Hessian by themselves.\n",
    "- But rather products of the form $v^TJ$, $Jv$, $v^TH$, $Hv$ where:\n",
    "    - $J$ is a Jacobian matrix of some outputs w.r.t model parameters.\n",
    "    - $H$ is the Hessian matrix of model parameters.\n",
    "    - $v$ is some constant vector.\n",
    "- Such products can be carried efficiently both in theory and in PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81294623",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's set a model and input for the following code parts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80c0693f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Linear(100, 10)\n",
    "x = torch.randn(5, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8595f2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Vector-Jacobian Product (VJP)\n",
    "\n",
    "- Let $f: \\mathbb{R}^W \\rightarrow \\mathbb{R}^C$ be a function with multiple outputs,\n",
    "with the model parameters an inputs.\n",
    "\n",
    "- Its Jacobain matrix $J_f(w) \\in \\mathbb{R}^{C \\times W}$. \n",
    "\n",
    "- Let $v \\in \\mathbb{R}^{C \\times 1}$ be a **constant** column vector.\n",
    "\n",
    "- Hence $v^TJ_f(w) \\in \\mathbb{R}^{1 \\times W}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae644cc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Instead of computing directly can push the (constant) vector inside the derivative:\n",
    "$$ v^TJ_f(w) = \\nabla_w (v^T f)$$\n",
    "- Compute like a regular gradient!\n",
    "- Code example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed1e4bd8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight 59.592594146728516\n",
      "bias 6.537693977355957\n"
     ]
    }
   ],
   "source": [
    "# Compute the Jacobian of the model outputs w.r.t model params multiplied by a constant vector\n",
    "\n",
    "model_outs = model(x)\n",
    "constant_vec = torch.randn((5, 10))\n",
    "\n",
    "# Dot product trick\n",
    "dot_prod = torch.dot(model_outs.reshape(-1),\n",
    "                       constant_vec.reshape(-1))\n",
    "\n",
    "# Compute grad\n",
    "dot_prod.backward()\n",
    "\n",
    "# Assert everything went ok \n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name} {torch.norm(param.grad).item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f6ea38",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Jacobian-Vector Product (JVP)\n",
    "\n",
    "- Let $f: \\mathbb{R}^W \\rightarrow \\mathbb{R}^C$ be a function with multiple outputs,\n",
    "with the model parameters an inputs.\n",
    "\n",
    "- Its Jacobain matrix $J_f(w) \\in \\mathbb{R}^{C \\times W}$. \n",
    "\n",
    "- Let $v \\in \\mathbb{R}^{W \\times 1}$ be a **constant** column vector.\n",
    "\n",
    "- Hence $J_f(w)v \\in \\mathbb{R}^{C \\times 1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a06ed4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Trick: consider $w(t) = w + vt$. Note that $w(0)=w$ and $\\dot{w}(0)=v$.\n",
    "- Consider now $g(t) := f(w(t))$. Note that $g: \\mathbb{R} \\rightarrow \\mathbb{R}^C$.\n",
    "- Note that $g(t)$ has a **single** input and **multiple** outputs, therby its derivative can be efficiently computed using a **forward mode AD**!\n",
    "- Howerver, $\\dot{g}(t) = J_f(w(t)) \\cdot \\dot{w}(t)$. In particular, $\\dot{g}(0) = J_f(w) \\cdot v$ which is exactly what we wanted to compute!\n",
    "- In practice, we don't need to actually add $t$ to the computational graph.\n",
    "    - Instead, just set the ```.grad``` of each parameter $w_i$ to be the corresponding entry of $v$, namely  $v_i$.\n",
    "    - Then, propagate gradients forward as before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60ab53b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* The PyTorch implementation of forward mode AD uses the context of dual numbers.\n",
    "* Each dual number consists of primal (```.val``` in our implementation) and tangent (```.grad``` in our implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "049110b9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# First, let's reset the gradients from the previous stage\n",
    "for p in model.parameters():\n",
    "    if p.requires_grad:\n",
    "        p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b93a04cd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JVP: tensor([[ 12.9747,   5.1294,  10.9688,   8.9754,   8.5315,   6.5809,  10.1785,\n",
      "          12.7517,   7.9965,   9.0048],\n",
      "        [  0.1476,   3.3589,   0.6669,   5.4944,   7.9856,   6.1468,   3.6670,\n",
      "           0.4737,  -0.4132,   5.0854],\n",
      "        [ -2.2306,  -1.5348,  -0.3690,  -0.5163,  -0.6187,  -3.8976,   7.6771,\n",
      "          -3.4724,  -0.1764,  -2.0414],\n",
      "        [ -5.7417,  -9.9915, -10.9281,  -7.3273,  -7.7580,  -8.8694,  -6.7291,\n",
      "          -7.1619,  -4.3795, -13.5380],\n",
      "        [ -3.7550,  -1.5950,  -2.0433,   0.9276,   2.2509,  -3.8973,   2.5104,\n",
      "           1.4369,  -3.9529,  -0.8301]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.autograd.forward_ad as fwAD\n",
    "\n",
    "params = {name: p for name, p in model.named_parameters()}\n",
    "constant_vec = {name: torch.rand_like(p) for name, p in params.items()}\n",
    "\n",
    "with fwAD.dual_level():\n",
    "    \n",
    "    # Manually set '.tangent' to propagate grads forward\n",
    "    for name, p in params.items():\n",
    "        delattr(model, name)\n",
    "        setattr(model, name, fwAD.make_dual(p, constant_vec[name]))\n",
    "    \n",
    "    # Apply model\n",
    "    out = model(x)\n",
    "    \n",
    "    # Extract the '.tangent' of the output node\n",
    "    jvp = fwAD.unpack_dual(out).tangent\n",
    "            \n",
    "# Assert everything went ok \n",
    "print(f\"JVP: {jvp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6841ed70",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Vector-Hessian and Hessian-Vector Products\n",
    "\n",
    "- $f: \\mathbb{R}^W \\rightarrow \\mathbb{R}$ be a single output function.\n",
    "- Observation: the Hessian of $f$ is Jacobian of its gradient:\n",
    "$$ \\nabla^2 f = J( \\nabla f )$$\n",
    "- Therefore, like before, to compute vector-hessian product, one can push the vector inside the jacobian:\n",
    "$$ v^T \\nabla^2 f = v^T J( \\nabla f) = \\nabla ( v^T (\\nabla f)) $$.\n",
    "- Note that this requires constructing the computational graph of $\\nabla f$!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3087956",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Reset model\n",
    "model = nn.Linear(100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3775348",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight 17.78291893005371\n",
      "bias 1.3691229820251465\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "constant_vec = [torch.randn_like(p) for p in model.parameters()]\n",
    "\n",
    "# Apply model\n",
    "out = model(x)\n",
    "# Apply arbitrary loss function for a scalar output\n",
    "loss = cross_entropy(out, \n",
    "                     torch.ones(x.shape[0]).type(torch.long))\n",
    "\n",
    "# Compute gradient and create its computational graph\n",
    "grad = torch.autograd.grad(loss, model.parameters(), create_graph=True)\n",
    "# Flatten copy of the gradient to be used later\n",
    "flat_grad = torch.cat([g.contiguous().view(-1) for g in grad])\n",
    "\n",
    "# Flatten vector\n",
    "flat_vec = torch.cat([v.contiguous().view(-1) for v in constant_vec])\n",
    "dot_prod = torch.dot(flat_grad, flat_vec)\n",
    "\n",
    "# Compute vhp\n",
    "dot_prod.backward()\n",
    "\n",
    "# Assert everything went ok \n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name} {torch.norm(param.grad).item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619c263b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* HVPs: essentially the same, left as an exercise to the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e345e6",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Credits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f2712c",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This tutorial was mostly written by Mitchell Keren Taraday.\n",
    "\n",
    "The \"Custom automatic differentiation with PyTorch\" chapter is taken from Aviv A. Rosenberg's tutorial.\n",
    "\n",
    "Image credits:\n",
    "- https://en.wikipedia.org/wiki/Automatic_differentiation"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
