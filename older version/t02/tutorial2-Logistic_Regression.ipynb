{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$\n",
    "\\newcommand{\\mat}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\mattr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\matinv}[1]{\\boldsymbol {#1}^{-1}}\n",
    "\\newcommand{\\vec}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\vectr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\rvar}[1]{\\mathrm {#1}}\n",
    "\\newcommand{\\rvec}[1]{\\boldsymbol{\\mathrm{#1}}}\n",
    "\\newcommand{\\diag}{\\mathop{\\mathrm {diag}}}\n",
    "\\newcommand{\\set}[1]{\\mathbb {#1}}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\newcommand{\\pderiv}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\bb}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\E}[2][]{\\mathbb{E}_{#1}\\left[#2\\right]}\n",
    "\\newcommand{\\given}[]{~\\middle\\vert~}\n",
    "$$\n",
    "\n",
    "# CS236781: Deep Learning\n",
    "# Tutorial 2: Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this tutorial, we will cover:\n",
    "\n",
    "* Basics of supervised learning\n",
    "    - Definitions\n",
    "    - Basics of optimization\n",
    "    - Types of errors\n",
    "* Classic ML example: Binary logistic regression from scratch using numpy (**self study**)\n",
    "* Multiclass logistic regression from scratch with PyTorch and autograd\n",
    "    - Optimization\n",
    "    - Writing training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:05.689208Z",
     "iopub.status.busy": "2022-03-31T05:57:05.688941Z",
     "iopub.status.idle": "2022-03-31T05:57:21.783611Z",
     "shell.execute_reply": "2022-03-31T05:57:21.783281Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:21.785948Z",
     "iopub.status.busy": "2022-03-31T05:57:21.785840Z",
     "iopub.status.idle": "2022-03-31T05:57:21.802646Z",
     "shell.execute_reply": "2022-03-31T05:57:21.802329Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['font.size'] = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Theory Reminders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The supervised learning framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We have a labeled dataset of $N$ labelled samples: $\\mathcal{S} = \\{ (\\vec{x}^i,y^i) \\}_{i=1}^N$, where\n",
    "- $\\vec{x}^i = \\left(x^i_1, \\dots, x^i_D\\right) \\in \\mathcal{X}$  is a **sample** or **feature vector**.\n",
    "- $y^i \\in \\mathcal{Y}$ is the **label**.\n",
    "- For classification with $C$ classes, $\\mathcal{Y} = \\{0,\\dots,C-1\\}$, so each $y^i$ is a **class label**.\n",
    "- Probabilistic perspective: assume each labeled sample $(\\vec{x}^i,y^i)\\sim\\mathcal{D}$,\n",
    "  i.e. each labeled sample is drawn from a joint distribution $\\mathcal{D}$ over $\\mathcal{X}\\times\\mathcal{Y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our **model** is a parametrized set of functions $\\mathcal{H}\\subseteq \\mathcal{Y}^{\\mathcal{X}}$.\n",
    "\n",
    "($\\mathcal{Y}^{\\mathcal{X}}$ is the set of all functions from $\\mathcal{X}$ to $\\mathcal{Y}$).\n",
    "\n",
    "From a probabilistic perspective, a model is a posterior: $P_{Y|\\vec{X}}(y, \\vec{x})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For example, the following hypothesis class\n",
    "$$\n",
    "\\mathcal{H} =\n",
    "\\left\\{ h: \\mathcal{X}\\rightarrow\\mathcal{Y}\n",
    "~\\vert~\n",
    "h(\\vec{x}) = \\varphi(\\vectr{w}\\vec{x}+b); \\vec{w}\\in\\set{R}^D,~b\\in\\set{R}\\right\\}\n",
    "$$\n",
    "where $\\varphi(\\cdot)$ is some nonlinear function, is known as the **perceptron** model, and is also called a **neuron** in the context of a neural network (due to it's biologically-inspired origin).\n",
    "\n",
    "\n",
    "| . | . |\n",
    "|---|---|\n",
    "| <img src=\"imgs/perceptron.png\" width=400 /> | <img src=\"imgs/neuron.png\" width=600 /> |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A **pointwise loss function** is some $\\ell:\\mathcal{Y}\\times\\mathcal{Y}\\to\\set{R}_{\\geq 0}$, e.g.\n",
    "- $\\ell(y,\\hat{y})=(y-\\hat{y})^2$\n",
    "- $\\ell(y,\\hat{y})= -y\\log(\\hat{y})-(1-y)\\log(1-\\hat{y})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The task: Given the training set $\\mathcal{S} = \\{ (\\vec{x}^i,y^i) \\}_{i=1}^N \\sim \\mathcal{D}$, find \n",
    "a predictor (hypothesis) $h: \\mathcal{X}\\to\\mathcal{Y}$ which minimizes **population loss**:\n",
    "\n",
    "$$\n",
    "L_{\\mathcal{D}}(h) = \\E[(\\vec{x},y)\\sim\\mathcal{D}]{\\ell(y, h(\\vec{x})}.\n",
    "$$\n",
    "\n",
    "This is also known as the **out-of-sample** loss. It is a deterministic quantity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Yes, it's the true expectation of an RV.\n",
    "\n",
    "Can we solve this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Joint-distribution $\\mathcal{D}$ is unknown!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Instead, we define an **empirical (in-sample) loss** $L_{\\mathcal{S}}(h)$ as the measure of how well a function $h\\in\\mathcal{H}$ fits the data $\\mathcal{S}$, for example\n",
    "$$\n",
    "L_{\\mathcal{S}}(h) = \\frac{1}{N} \\sum_{i=1}^{N} \\ell(h(\\vec{x}^i), y^i) + R(h)\n",
    "$$\n",
    "where\n",
    "\n",
    "- $\\ell(y,\\hat{y})$ is some pointwise loss (depends on the data).\n",
    "- $R(h)$ is a regularization term (depends only on the model).\n",
    "\n",
    "Is this is a deterministic quantity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The model is **trained** by updating its parameters to improve its performance on some data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We wish to find a parametrization $\\vec{w}^\\ast$ of our model $h^{\\ast}_{\\mathcal{S}}(\\vec{x};\\vec{w}^\\ast)\\in\\mathcal{H}$ such that\n",
    "$$\n",
    "h^{\\ast}_{\\mathcal{S}} = \\arg\\min_{h\\in\\mathcal{H}} L_{\\mathcal{S}}(h)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Usual approach: descent-based optimization (will be covered in next lecture)\n",
    "$$\n",
    "\\vec{w}_{k+1} \\leftarrow \\vec{w}_{k} - \\eta_k \\vec{d}_{k}\n",
    "$$\n",
    "\n",
    "Where $\\vec{d}_k$ is a **descent direction** and $\\eta_k$ is the step size at step $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Most common choice for $\\vec{d}_k$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Gradient descent: $\\vec{d}_k = \\nabla_{\\vec{w}_{k}} L(\\vec{w}_{k})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Will we find the optimal solution, $\\vec{w}^\\ast$, though?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Generally the loss is non-convex and we have no guarantee of converging to the global optimum!\n",
    "$\\Rightarrow$ **Optimization Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/sgd2d_2.png\" width=800 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Gradient descent (GD) has the advantage of being extremely simple to apply, and requires only first-order derivatives.\n",
    "\n",
    "However it provides no guarantees for convergence on non-convex objectives.\n",
    "\n",
    "Later in the course we'll learn about variants of GD which perform well in practice even on the non-convex objectives we'll face in deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Generalization and Expressiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We've talked about optimization error.\n",
    "\n",
    "What are **other** sources of errors in our learning approach (besides optimization)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We train to minimize our empirical loss $L_\\mathcal{S}$ instead of the population loss $L_\\mathcal{D}$ $\\Rightarrow$ **Generalization Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We only consider a limited set of possible functions, $\\mathcal{H}$ $\\Rightarrow$ **Approximation Error**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"imgs/error_types.png\" width=900 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How do we mitigate these errors in the practice of machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Optimization error: Mini batches; GD variants like stochastic gradient, Momentum, Adam, LR scheduling, etc (we'll see later in the course)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Generalization error: Get more data; get data which better represents $\\mathcal{D}$; train-test splits; cross validation; early stopping; regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Approximation error: Use a powerful hypothesis class (e.g. DNN); more parameters; \"inductive bias\" - tailoring the model to the domain (e.g. CNN for images)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Binary Logistic Regression\n",
    "\n",
    "Actually a **classification** model. We're trying to classify data into 2 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Domain: $\\vec{x}^i \\in \\set{R}^D$\n",
    "- Target: $y^i \\in \\{0,1\\}$\n",
    "- Model: $\\hat{y} = h(\\vec{x}) = \\sigma(\\vectr{w}\\vec{x}+b)$, where $\\sigma(\\vec{z})$ is the **logistic function**:\n",
    "    $$\\sigma(\\vec{z}) = \\frac{1}{1+e^{-\\vec{z}}}.$$\n",
    "    This function maps the real line onto $[0,1]$.\n",
    "- Probabilistic interpretation: $\\hat{y}=P(\\rvar{Y}=1|\\rvec{X}=\\vec{x})$.\n",
    "\n",
    "  This is a posterior probability function for our target variable $\\rvar{Y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:21.806138Z",
     "iopub.status.busy": "2022-03-31T05:57:21.806020Z",
     "iopub.status.idle": "2022-03-31T05:57:21.821968Z",
     "shell.execute_reply": "2022-03-31T05:57:21.821667Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def logistic(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "x = np.arange(-5, 5, .01)\n",
    "y_hat = logistic(x)\n",
    "\n",
    "plt.plot(x, y_hat, label='$\\sigma(z)$')\n",
    "plt.grid(True); plt.xlabel('z'); plt.legend(); plt.title('The logistic function');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To optimize, we minimize the **negative log-likelihood** (equivalent to maximizing likelihood, i.e. MLE) of the parameters $\\vec{w}$:\n",
    "\n",
    "$$\n",
    "\\bb{w}^\\ast = \\mathrm{arg}\\max_{ \\bb{w}} \\prod_{i=1}^n P(y_i | \\bb{x}_i;\\vec{w}) = \\mathrm{arg}\\min_{ \\bb{w}} \\sum_{i=1}^n -\\log P(y_i | \\bb{x}_i; \\vec{w})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Based on this we define our loss $L(\\bb{w})$ (what we minimize) as,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "L(\\bb{w}) &\\triangleq \\sum_{i=1}^n -\\log P(y_i | \\bb{x}_i; \\vec{w})\\\\\n",
    "&= \\sum_{i=1}^n -y_i \\log P(y_i=1 | \\bb{x}_i; \\vec{w}) - (1-y_i) \\log P(y_i=0 | \\bb{x}_i; \\vec{w}) \\\\\n",
    "&= \\sum_{i=1}^n -y_i \\log \\hat{y}_i - (1-y_i) \\log(1-\\hat{y}_i)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The resulting pointwise loss is also known as **cross-entropy**:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\ell(y, \\hat{y}) &=  - y \\log(\\hat{y}) - (1-y) \\log(1-\\hat{y}) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "(The \"cross\" here is between the distribution of the samples $y^i$ and the distribution of the predictions $\\hat{y}^i$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Optimization scheme: No closed form solution, but loss is **convex** so gradient-based approach leads to global optimum.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\ell(y, \\hat{y}) &=  - y \\log(\\hat{y}) - (1-y) \\log(1-\\hat{y}) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Let's plot this loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.046901Z",
     "iopub.status.busy": "2022-03-31T05:57:22.046787Z",
     "iopub.status.idle": "2022-03-31T05:57:22.158748Z",
     "shell.execute_reply": "2022-03-31T05:57:22.158430Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_y0 = -np.log(1-y_hat)\n",
    "loss_y1 = -np.log(y_hat)\n",
    "plt.plot(y_hat, loss_y0, label='$\\ell(y=0,\\hat{y})$')\n",
    "plt.plot(y_hat, loss_y1, label='$\\ell(y=1,\\hat{y})$')\n",
    "plt.grid(True); plt.xlabel('$\\hat{y}$'); plt.legend(); plt.title('Cross entropy loss');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To apply gradient descent, we need to know the gradient of the loss w.r.t. the parameters $\\vec{w}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Exercise: Prove that for the cross entropy loss with binary logistic regression, it holds that:\n",
    "$$\n",
    "\\pderiv{\\ell(y,\\hat{y})}{\\vec{w}}= (\\hat{y}-y)\\vec{x}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Proof:\n",
    "\n",
    "First, we apply the chain-rule\n",
    "$$\n",
    "\\pderiv{\\ell(y,\\hat{y})}{\\vec{w}}=\\pderiv{\\ell}{\\hat{y}}\\cdot\\pderiv{\\hat{y}}{z}\\cdot\\pderiv{z}{\\vec{w}},\n",
    "$$\n",
    "where $z=\\vectr{w}\\vec{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Now, just by definition,\n",
    "$$\n",
    "\\begin{align}\n",
    "\\pderiv{\\ell}{\\hat{y}}&=-\\frac{y}{\\hat{y}}+\\frac{1-y}{1-\\hat{y}}=\\frac{\\hat{y}-y}{\\hat{y}(1-\\hat{y})}\\\\\n",
    "\\pderiv{\\hat{y}}{z}&=\\frac{e^{-z}}{(1+e^{-z})^2}=\n",
    "\\frac{e^{-z}}{1+e^{-z}}\\cdot\\frac{1}{1+e^{-z}}=(1-\\sigma(z))\\sigma(z)=(1-\\hat{y})\\hat{y}\\\\\n",
    "\\pderiv{z}{\\vec{w}}&=\\vec{x}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 1: Binary Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As a warm up exercise, let's see a quick example of implementing this algorithm and training it from scratch using just `numpy` (and a toy dataset from `sklearn`).\n",
    "\n",
    "This is a classic and very simple example of implementing and training a machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dataset\n",
    "\n",
    "The `scikit-learn` library comes with a few [toy datasets](http://scikit-learn.org/stable/datasets/index.html#toy-datasets) that are fun to quickly train small models on.\n",
    "\n",
    "As an example we'll load the Wisconsin-breast cancer database:\n",
    "- 569 samples of cancer patients\n",
    "- 30 features: various properties of tumor cells extracted from images\n",
    "- 2 classes: Tumor is either Benign or Malignant\n",
    "\n",
    "We'll apply the basic machine learning approach we saw above: binary logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.160877Z",
     "iopub.status.busy": "2022-03-31T05:57:22.160761Z",
     "iopub.status.idle": "2022-03-31T05:57:22.305758Z",
     "shell.execute_reply": "2022-03-31T05:57:22.305466Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features=30\n",
      "feature names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "target  names: ['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets\n",
    "\n",
    "ds_cancer = sklearn.datasets.load_breast_cancer()\n",
    "feature_names = ds_cancer.feature_names\n",
    "target_names = ds_cancer.target_names\n",
    "n_features = len(feature_names)\n",
    "\n",
    "print(f'{n_features=}')\n",
    "print(f'feature names: {feature_names}')\n",
    "print(f'target  names: {target_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.307551Z",
     "iopub.status.busy": "2022-03-31T05:57:22.307445Z",
     "iopub.status.idle": "2022-03-31T05:57:22.324556Z",
     "shell.execute_reply": "2022-03-31T05:57:22.324276Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (569, 30)\n",
      "y: (569,)\n"
     ]
    }
   ],
   "source": [
    "X, y = ds_cancer.data, ds_cancer.target\n",
    "n_samples = len(y)\n",
    "\n",
    "print(f'X: {X.shape}')\n",
    "print(f'y: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.326309Z",
     "iopub.status.busy": "2022-03-31T05:57:22.326189Z",
     "iopub.status.idle": "2022-03-31T05:57:22.351440Z",
     "shell.execute_reply": "2022-03-31T05:57:22.351125Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>13.610</td>\n",
       "      <td>582.7</td>\n",
       "      <td>0.08625</td>\n",
       "      <td>0.05871</td>\n",
       "      <td>2.8610</td>\n",
       "      <td>0.014880</td>\n",
       "      <td>0.01465</td>\n",
       "      <td>35.27</td>\n",
       "      <td>0.1265</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>MALIGNANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>6.981</td>\n",
       "      <td>143.5</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.07818</td>\n",
       "      <td>1.5530</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.02659</td>\n",
       "      <td>19.54</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>12.180</td>\n",
       "      <td>458.7</td>\n",
       "      <td>0.02383</td>\n",
       "      <td>0.05677</td>\n",
       "      <td>1.1830</td>\n",
       "      <td>0.006098</td>\n",
       "      <td>0.01447</td>\n",
       "      <td>32.84</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>9.876</td>\n",
       "      <td>298.3</td>\n",
       "      <td>0.06154</td>\n",
       "      <td>0.06322</td>\n",
       "      <td>1.5280</td>\n",
       "      <td>0.021960</td>\n",
       "      <td>0.01609</td>\n",
       "      <td>26.83</td>\n",
       "      <td>0.1559</td>\n",
       "      <td>0.09749</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>10.490</td>\n",
       "      <td>336.1</td>\n",
       "      <td>0.02995</td>\n",
       "      <td>0.06481</td>\n",
       "      <td>2.3020</td>\n",
       "      <td>0.022190</td>\n",
       "      <td>0.02710</td>\n",
       "      <td>23.31</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>0.03203</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>13.110</td>\n",
       "      <td>530.2</td>\n",
       "      <td>0.20710</td>\n",
       "      <td>0.07692</td>\n",
       "      <td>2.4100</td>\n",
       "      <td>0.029120</td>\n",
       "      <td>0.01547</td>\n",
       "      <td>22.40</td>\n",
       "      <td>0.1862</td>\n",
       "      <td>0.19860</td>\n",
       "      <td>MALIGNANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>11.640</td>\n",
       "      <td>412.5</td>\n",
       "      <td>0.07070</td>\n",
       "      <td>0.06520</td>\n",
       "      <td>2.1550</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.01565</td>\n",
       "      <td>29.26</td>\n",
       "      <td>0.1688</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>12.360</td>\n",
       "      <td>466.7</td>\n",
       "      <td>0.02643</td>\n",
       "      <td>0.06066</td>\n",
       "      <td>0.8484</td>\n",
       "      <td>0.010470</td>\n",
       "      <td>0.01251</td>\n",
       "      <td>27.49</td>\n",
       "      <td>0.1184</td>\n",
       "      <td>0.08442</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>22.270</td>\n",
       "      <td>1509.0</td>\n",
       "      <td>0.42640</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>10.0500</td>\n",
       "      <td>0.086680</td>\n",
       "      <td>0.03112</td>\n",
       "      <td>28.01</td>\n",
       "      <td>0.1701</td>\n",
       "      <td>0.29100</td>\n",
       "      <td>MALIGNANT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>11.340</td>\n",
       "      <td>396.5</td>\n",
       "      <td>0.05133</td>\n",
       "      <td>0.06529</td>\n",
       "      <td>1.5970</td>\n",
       "      <td>0.015570</td>\n",
       "      <td>0.01568</td>\n",
       "      <td>29.15</td>\n",
       "      <td>0.1699</td>\n",
       "      <td>0.08278</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean area  mean concavity  mean fractal dimension  \\\n",
       "100       13.610      582.7         0.08625                 0.05871   \n",
       "101        6.981      143.5         0.00000                 0.07818   \n",
       "102       12.180      458.7         0.02383                 0.05677   \n",
       "103        9.876      298.3         0.06154                 0.06322   \n",
       "104       10.490      336.1         0.02995                 0.06481   \n",
       "105       13.110      530.2         0.20710                 0.07692   \n",
       "106       11.640      412.5         0.07070                 0.06520   \n",
       "107       12.360      466.7         0.02643                 0.06066   \n",
       "108       22.270     1509.0         0.42640                 0.07039   \n",
       "109       11.340      396.5         0.05133                 0.06529   \n",
       "\n",
       "     perimeter error  compactness error  symmetry error  worst texture  \\\n",
       "100           2.8610           0.014880         0.01465          35.27   \n",
       "101           1.5530           0.010840         0.02659          19.54   \n",
       "102           1.1830           0.006098         0.01447          32.84   \n",
       "103           1.5280           0.021960         0.01609          26.83   \n",
       "104           2.3020           0.022190         0.02710          23.31   \n",
       "105           2.4100           0.029120         0.01547          22.40   \n",
       "106           2.1550           0.023100         0.01565          29.26   \n",
       "107           0.8484           0.010470         0.01251          27.49   \n",
       "108          10.0500           0.086680         0.03112          28.01   \n",
       "109           1.5970           0.015570         0.01568          29.15   \n",
       "\n",
       "     worst smoothness  worst concave points      CLASS  \n",
       "100            0.1265               0.11840  MALIGNANT  \n",
       "101            0.1584               0.00000     BENIGN  \n",
       "102            0.1123               0.07431     BENIGN  \n",
       "103            0.1559               0.09749     BENIGN  \n",
       "104            0.1219               0.03203     BENIGN  \n",
       "105            0.1862               0.19860  MALIGNANT  \n",
       "106            0.1688               0.12180     BENIGN  \n",
       "107            0.1184               0.08442     BENIGN  \n",
       "108            0.1701               0.29100  MALIGNANT  \n",
       "109            0.1699               0.08278     BENIGN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load into a pandas dataframe and show some samples\n",
    "y_names = np.full_like(y, target_names[0].upper(), dtype=target_names.dtype)\n",
    "y_names[y==1] = target_names[1].upper()\n",
    "\n",
    "df_cancer = pd.DataFrame(data=X, columns=ds_cancer.feature_names)\n",
    "df_cancer = df_cancer.assign(CLASS=y_names)\n",
    "df_cancer.iloc[100:110, 0::3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.353134Z",
     "iopub.status.busy": "2022-03-31T05:57:22.353029Z",
     "iopub.status.idle": "2022-03-31T05:57:22.426369Z",
     "shell.execute_reply": "2022-03-31T05:57:22.426076Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: X=(398, 30) y=(398,)\n",
      "test : X=(171, 30) y=(171,)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f'train: X={X_train.shape} y={y_train.shape}')\n",
    "print(f'test : X={X_test.shape} y={y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.428140Z",
     "iopub.status.busy": "2022-03-31T05:57:22.428029Z",
     "iopub.status.idle": "2022-03-31T05:57:22.445197Z",
     "shell.execute_reply": "2022-03-31T05:57:22.444944Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu_X.shape=(30,), sigma_X.shape=(30,)\n"
     ]
    }
   ],
   "source": [
    "# Standardize the features\n",
    "\n",
    "# Note: each feature is standardized individually:\n",
    "mu_X = np.mean(X_train, axis=0) # (N, D) -> (D,)\n",
    "sigma_X = np.std(X_train, axis=0)\n",
    "\n",
    "# Note: Broadcasting (N, D) with (D,) -> (N, D)\n",
    "X_train_sc = (X_train - mu_X) / sigma_X \n",
    "\n",
    "# Note: Test set must be transformed identically to training set\n",
    "X_test_sc = (X_test - mu_X) / sigma_X\n",
    "\n",
    "print(f'{mu_X.shape=}, {sigma_X.shape=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model Implementation\n",
    "\n",
    "We'll implement based on the above definitions.\n",
    "\n",
    "The model will be implemented as a class with an API that conforms to the `sklearn` models, specifically see\n",
    "`sklearn`'s [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.446969Z",
     "iopub.status.busy": "2022-03-31T05:57:22.446870Z",
     "iopub.status.idle": "2022-03-31T05:57:22.465612Z",
     "shell.execute_reply": "2022-03-31T05:57:22.465336Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryLogisticRegression(object):\n",
    "    def __init__(self, n_iter=100, learn_rate=0.1):\n",
    "        self.n_iter = n_iter\n",
    "        self.learn_rate = learn_rate\n",
    "        self._w = None\n",
    "        \n",
    "    def _add_bias(self, X: np.ndarray):\n",
    "        # Add a bias term column\n",
    "        ones_col = np.ones((X.shape[0], 1))\n",
    "        return np.hstack([ones_col, X])\n",
    "    \n",
    "    def predict_proba(self, X: np.ndarray, add_bias=True):\n",
    "        X = self._add_bias(X) if add_bias else X\n",
    "        \n",
    "        # Apply logistic model\n",
    "        z = np.dot(X, self.weights) # (N, D) * (D,)\n",
    "        return logistic(z) # shape (N,)\n",
    "    \n",
    "    def predict(self, X: np.ndarray):\n",
    "        proba = self.predict_proba(X)\n",
    "        \n",
    "        # Apply naive threshold of .5\n",
    "        return np.array(proba > .5, dtype=np.int)\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        n, d = X.shape # X is (N, D), y is (N,)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._w = np.random.randn(d + 1) * 0.1\n",
    "        \n",
    "        Xb = self._add_bias(X)\n",
    "\n",
    "        # Training loop\n",
    "        self._losses = []\n",
    "        for i in range(self.n_iter):\n",
    "            # Predicted probabilities\n",
    "            y_hat = self.predict_proba(Xb, add_bias=False)\n",
    "            \n",
    "            # Pointwise loss\n",
    "            loss = -y.dot(np.log(y_hat)) - ((1 - y).dot(np.log(1 - y_hat)))\n",
    "            \n",
    "            # See Exercise for gradient derivation\n",
    "            loss_grad = 1/n * Xb.T.dot(y_hat - y)  # dl/dw: (D+1, N) * (N,)\n",
    "            \n",
    "            # Optimization step\n",
    "            self._w += -self.learn_rate * loss_grad\n",
    "            self._losses.append(loss)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    @property\n",
    "    def weights(self):\n",
    "        if self._w is None:\n",
    "            raise ValueError(\"Model is not fitted\")\n",
    "        return self._w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.467358Z",
     "iopub.status.busy": "2022-03-31T05:57:22.467275Z",
     "iopub.status.idle": "2022-03-31T05:57:22.563355Z",
     "shell.execute_reply": "2022-03-31T05:57:22.563067Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the model to the training data\n",
    "lr_model = BinaryLogisticRegression(n_iter=500, learn_rate=0.01)\n",
    "lr_model.fit(X_train_sc, y_train)\n",
    "\n",
    "plt.plot(lr_model._losses, label='$L_{\\mathcal{S}}$');\n",
    "plt.xlabel('training iteration'); plt.legend(); plt.grid(True); plt.title('Train loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.565187Z",
     "iopub.status.busy": "2022-03-31T05:57:22.565084Z",
     "iopub.status.idle": "2022-03-31T05:57:22.581336Z",
     "shell.execute_reply": "2022-03-31T05:57:22.581061Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set accuracy: 96.73%\n",
      "test set accuracy: 95.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/71/vjkhnhh91ljfc2nsmsq9wl5r0000gn/T/ipykernel_74416/933480850.py:23: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return np.array(proba > .5, dtype=np.int)\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = lr_model.predict(X_train_sc)\n",
    "train_acc = np.mean(y_train_pred == y_train)\n",
    "print(f'train set accuracy: {train_acc*100:.2f}%')\n",
    "\n",
    "y_test_pred = lr_model.predict(X_test_sc)\n",
    "test_acc = np.mean(y_test_pred == y_test)\n",
    "print(f'test set accuracy: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part 2: Multiclass Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What if we have $C$ classes? Can we still use logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A nave approach is to train $C$ binary logistic regression classifiers, for example in a One vs. Rest scheme,\n",
    "and then predict based on the classifier returning the greatest probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One major drawback of this approach is that it doesn't model the probability distribution over the possible classes, $P_{\\vec{Y}|\\vec{X}}$. \n",
    "\n",
    "For example, a sample might be classified as class A with probability $0.8$ and class $B$ with $0.7$ since nothing constrains the different classifiers.\n",
    "\n",
    "Also, without *calibrating* each model, their raw scores cannont reliably be compared even though they're in the same range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The softmax function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Softmax** is a function which can generate a probability distribution for our $C$ classes given raw prediction scores. It's defined as follows:\n",
    "\n",
    "$$\n",
    "\\mathrm{softmax}(\\vec{z}) = \\frac{e^{\\vec{z}}}{\\sum_{j=1}^{C} e^{z_j}}\n",
    "$$\n",
    "\n",
    "note that this is a vector valued, multivariate function. The exponent in the enumerator operates elementwise.\n",
    "\n",
    "The result of softmax is a vector with elements in $[0,1]$ that all sum to $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The multiclass model\n",
    "\n",
    "Our model can now be defined as\n",
    "\n",
    "$$\\hat{\\vec{y}} = h(\\vec{x}) = \\mathrm{softmax}(\\mattr{W}\\vec{x}+\\vec{b})$$\n",
    "\n",
    "where,\n",
    "- $\\hat{\\vec{y}}$ is a $C\\times 1$ vector of class probabilities.\n",
    "- ${\\vec{x}}$ is a $D\\times 1$ sample.\n",
    "- $\\mat{W}$ is a $D\\times C$ matrix representing the per-class weights.\n",
    "- $\\vec{b}$ is a per-class bias vector of length $C$.\n",
    "\n",
    "Probabilistic interpretation: $\\hat{y}_j = P(\\rvar{Y}=j|\\rvec{X}=\\vec{x})$.\n",
    "\n",
    "While not very powerful on it's own, this type of model is commonly found at the end of deep neural networks performing classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To train such a model we need our labels to also be singleton probability distributions instead of simply the number of the correct class.\n",
    "\n",
    "We'll transform our labels to a 1-hot encoded vector corresponding to a delta distribution.\n",
    "For example, if $y^i=j$ then we'll create\n",
    "$$\n",
    "\\vec{y}^i = [0,\\dots,0,\\underbrace{1}_{j\\mathrm{th\\ component}},0,\\dots,0]^\\top\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Cross-Entropy loss\n",
    "\n",
    "After defining the 1-hot label vectors, the multiclass extension of the binary cross-entropy is straightforward:\n",
    "\n",
    "$$\n",
    "\\ell(\\vec{y}, \\hat{\\vec{y}}) = - \\vectr{y} \\log(\\hat{\\vec{y}})\n",
    "$$\n",
    "\n",
    "Note that only the probability assigned to the correct class affects the loss.\n",
    "\n",
    "Minimizing this cross entropy can be interpreted as trying to move the probability distribution of model predictions towards the singleton distribution of the appropriate class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This time we'll tackle an image classification task, the MNIST database of handwritten digits.\n",
    "\n",
    "Today this is also considered a toy dataset, even though it was used in the past to benchmark classification algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:22.583530Z",
     "iopub.status.busy": "2022-03-31T05:57:22.583432Z",
     "iopub.status.idle": "2022-03-31T05:57:23.673426Z",
     "shell.execute_reply": "2022-03-31T05:57:23.673015Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.autograd\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms\n",
    "import plot_utils\n",
    "\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:23.675467Z",
     "iopub.status.busy": "2022-03-31T05:57:23.675341Z",
     "iopub.status.idle": "2022-03-31T05:57:23.728446Z",
     "shell.execute_reply": "2022-03-31T05:57:23.728149Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/avivr/mambaforge/envs/cs236781-tutorials/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/runner/miniforge3/conda-bld/pytorch-recipe_1643121243037/work/torch/csrc/utils/tensor_numpy.cpp:189.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# Define the transforms that should be applied to each image in the dataset before returning it\n",
    "tf_ds = torchvision.transforms.ToTensor()\n",
    "\n",
    "batch_size = 64\n",
    "data_root = os.path.expanduser(\"~/.pytorch-datasets\")\n",
    "\n",
    "# Training and test datasets\n",
    "ds_train, ds_test = [\n",
    "    torchvision.datasets.MNIST(root=data_root, download=True, train=train, transform=tf_ds)   \n",
    "    for train in [True, False]\n",
    "]\n",
    "\n",
    "# Data loaders\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size, shuffle=True)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=len(ds_test))\n",
    "\n",
    "x0, y0 = ds_train[0]\n",
    "n_features = torch.numel(x0)\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:23.730338Z",
     "iopub.status.busy": "2022-03-31T05:57:23.730231Z",
     "iopub.status.idle": "2022-03-31T05:57:23.909829Z",
     "shell.execute_reply": "2022-03-31T05:57:23.909349Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0: torch.Size([1, 28, 28]), y0: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show first few samples\n",
    "print(f'x0: {x0.shape}, y0: {y0}')\n",
    "plot_utils.dataset_first_n(ds_train, 10, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that when training, we're actually working with **batches** of samples (we'll learn about SGD in the sebsequent lectures/tutorials):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:23.911944Z",
     "iopub.status.busy": "2022-03-31T05:57:23.911831Z",
     "iopub.status.idle": "2022-03-31T05:57:23.950133Z",
     "shell.execute_reply": "2022-03-31T05:57:23.949826Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0, y0 = next(iter(dl_train))\n",
    "x0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This time we'll use `pytorch` tensors and its [`autograd`](https://pytorch.org/docs/stable/autograd.html) functionality to implement our model.\n",
    "\n",
    "This means we wont have to implement any gradient calculations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First, let's implement $\\mathrm{softmax}(\\cdot)$. We need a small numerical trick to prevent large numbers from exploding the exponentiation. You can verify that this doesn't influence the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:23.952303Z",
     "iopub.status.busy": "2022-03-31T05:57:23.952173Z",
     "iopub.status.idle": "2022-03-31T05:57:23.974439Z",
     "shell.execute_reply": "2022-03-31T05:57:23.974110Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def softmax(z: Tensor) -> Tensor:\n",
    "    \"\"\"\n",
    "    softmax(z)= e^(z) / sum(e^z)\n",
    "    :param z: A batch of C class scores per N samples, shape (N, C).\n",
    "    :returns: softmax per sample, of shape (N, C).\n",
    "    \"\"\"\n",
    "\n",
    "    # normalization trick to prevent numerical instability:\n",
    "    # shift so that the highest class score (per sample) is 0\n",
    "    zmax, _ = torch.max(z, dim=1, keepdim=True)\n",
    "    z = z - zmax # note broadcasting: (N,C) - (N,1)\n",
    "    \n",
    "    exp_z = torch.exp(z) # (N, C)\n",
    "    sum_exp = torch.sum(exp_z, dim=1, keepdim=True) # (N, 1)\n",
    "    return exp_z / sum_exp # probabilities, (N,C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's test our softmax and calculate its derivative with `autograd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:23.976580Z",
     "iopub.status.busy": "2022-03-31T05:57:23.976457Z",
     "iopub.status.idle": "2022-03-31T05:57:24.016133Z",
     "shell.execute_reply": "2022-03-31T05:57:24.015840Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1167, 0.7073, 0.1760],\n",
       "        [0.0702, 0.7838, 0.1460],\n",
       "        [0.0755, 0.4197, 0.5048],\n",
       "        [0.0205, 0.1090, 0.8704]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.randn(size=(4,3), requires_grad=True)\n",
    "y = softmax(z)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.017936Z",
     "iopub.status.busy": "2022-03-31T05:57:24.017817Z",
     "iopub.status.idle": "2022-03-31T05:57:24.046073Z",
     "shell.execute_reply": "2022-03-31T05:57:24.045800Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]),)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = softmax(z)\n",
    "L = torch.sum(y) # scalar function of z \n",
    "\n",
    "# Calculate gradient: dL/dz\n",
    "torch.autograd.grad(L, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Instead of calling `autograd.grad()` directly with specific input tensors, `pytorch` provides us with a way to calculate the derivative of a tensor w.r.t. all the tensors which are **leaves** in it's computation graph (only $\\vec{z}$ in this case).\n",
    "\n",
    "This can be done by calling `.backward()` on a scalar tensor.\n",
    "As a result, the `.grad` property of leaf tensors will be populated with the gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.047850Z",
     "iopub.status.busy": "2022-03-31T05:57:24.047737Z",
     "iopub.status.idle": "2022-03-31T05:57:24.069034Z",
     "shell.execute_reply": "2022-03-31T05:57:24.068735Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " tensor([[0., 0., 0.]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example with two leaves in the computaion graph\n",
    "z1 = torch.randn(size=(4,3), requires_grad=True)\n",
    "z2 = torch.randn(size=(1,3), requires_grad=True)\n",
    "z = z1 - z2\n",
    "\n",
    "y = softmax(z)\n",
    "L = torch.sum(y) # scalar function of z \n",
    "L.backward()     # Calculate derivative w.r.t. all leaves\n",
    "\n",
    "z1.grad, z2.grad # The leaves z1, z2 will have their .grad populated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here's the resulting computation graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.070855Z",
     "iopub.status.busy": "2022-03-31T05:57:24.070744Z",
     "iopub.status.idle": "2022-03-31T05:57:24.189514Z",
     "shell.execute_reply": "2022-03-31T05:57:24.189143Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.42.3 (20191010.1750)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"206pt\" height=\"534pt\"\n",
       " viewBox=\"0.00 0.00 206.48 534.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 530)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-530 202.48,-530 202.48,4 -4,4\"/>\n",
       "<!-- 140635893099312 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140635893099312</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"126.24,-30 72.24,-30 72.24,0 126.24,0 126.24,-30\"/>\n",
       "<text text-anchor=\"middle\" x=\"99.24\" y=\"-6\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 140635892678912 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140635892678912</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"142.27,-84 56.21,-84 56.21,-66 142.27,-66 142.27,-84\"/>\n",
       "<text text-anchor=\"middle\" x=\"99.24\" y=\"-72\" font-family=\"monospace\" font-size=\"10.00\">SumBackward0</text>\n",
       "</g>\n",
       "<!-- 140635892678912&#45;&gt;140635893099312 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>140635892678912&#45;&gt;140635893099312</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99.24,-65.94C99.24,-59.31 99.24,-49.57 99.24,-40.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.74,-40.24 99.24,-30.24 95.74,-40.24 102.74,-40.24\"/>\n",
       "</g>\n",
       "<!-- 140635892680688 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140635892680688</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"139.15,-138 59.33,-138 59.33,-120 139.15,-120 139.15,-138\"/>\n",
       "<text text-anchor=\"middle\" x=\"99.24\" y=\"-126\" font-family=\"monospace\" font-size=\"10.00\">DivBackward0</text>\n",
       "</g>\n",
       "<!-- 140635892680688&#45;&gt;140635892678912 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140635892680688&#45;&gt;140635892678912</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99.24,-119.88C99.24,-113.05 99.24,-103.03 99.24,-94.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.74,-94.24 99.24,-84.24 95.74,-94.24 102.74,-94.24\"/>\n",
       "</g>\n",
       "<!-- 140635892679776 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140635892679776</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"140.44,-246 58.04,-246 58.04,-228 140.44,-228 140.44,-246\"/>\n",
       "<text text-anchor=\"middle\" x=\"99.24\" y=\"-234\" font-family=\"monospace\" font-size=\"10.00\">ExpBackward0</text>\n",
       "</g>\n",
       "<!-- 140635892679776&#45;&gt;140635892680688 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140635892679776&#45;&gt;140635892680688</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M95.28,-227.8C91.32,-219.14 85.52,-204.97 83.24,-192 80.56,-176.78 85.51,-159.8 90.59,-147.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"93.79,-148.89 94.73,-138.33 87.42,-146 93.79,-148.89\"/>\n",
       "</g>\n",
       "<!-- 140635892679488 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>140635892679488</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"178.27,-192 92.21,-192 92.21,-174 178.27,-174 178.27,-192\"/>\n",
       "<text text-anchor=\"middle\" x=\"135.24\" y=\"-180\" font-family=\"monospace\" font-size=\"10.00\">SumBackward1</text>\n",
       "</g>\n",
       "<!-- 140635892679776&#45;&gt;140635892679488 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>140635892679776&#45;&gt;140635892679488</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M104.86,-227.88C109.91,-220.59 117.46,-209.68 123.77,-200.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.72,-202.45 129.53,-192.24 120.96,-198.47 126.72,-202.45\"/>\n",
       "</g>\n",
       "<!-- 140635892680496 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140635892680496</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"141,-300 57.48,-300 57.48,-282 141,-282 141,-300\"/>\n",
       "<text text-anchor=\"middle\" x=\"99.24\" y=\"-288\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 140635892680496&#45;&gt;140635892679776 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140635892680496&#45;&gt;140635892679776</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99.24,-281.88C99.24,-275.05 99.24,-265.03 99.24,-256.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"102.74,-256.24 99.24,-246.24 95.74,-256.24 102.74,-256.24\"/>\n",
       "</g>\n",
       "<!-- 140635892681552 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140635892681552</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"141,-408 57.48,-408 57.48,-390 141,-390 141,-408\"/>\n",
       "<text text-anchor=\"middle\" x=\"99.24\" y=\"-396\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 140635892681552&#45;&gt;140635892680496 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140635892681552&#45;&gt;140635892680496</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M95.28,-389.8C91.32,-381.14 85.52,-366.97 83.24,-354 80.56,-338.78 85.51,-321.8 90.59,-309.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"93.79,-310.89 94.73,-300.33 87.42,-308 93.79,-310.89\"/>\n",
       "</g>\n",
       "<!-- 140635892680544 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>140635892680544</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"176.6,-354 91.88,-354 91.88,-336 176.6,-336 176.6,-354\"/>\n",
       "<text text-anchor=\"middle\" x=\"134.24\" y=\"-342\" font-family=\"monospace\" font-size=\"10.00\">MaxBackward0</text>\n",
       "</g>\n",
       "<!-- 140635892681552&#45;&gt;140635892680544 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140635892681552&#45;&gt;140635892680544</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M104.71,-389.88C109.61,-382.59 116.95,-371.68 123.09,-362.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.01,-364.49 128.69,-354.24 120.21,-360.58 126.01,-364.49\"/>\n",
       "</g>\n",
       "<!-- 140635892682656 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140635892682656</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"90.72,-462 -0.24,-462 -0.24,-444 90.72,-444 90.72,-462\"/>\n",
       "<text text-anchor=\"middle\" x=\"45.24\" y=\"-450\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140635892682656&#45;&gt;140635892681552 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140635892682656&#45;&gt;140635892681552</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M53.68,-443.88C61.56,-436.29 73.52,-424.76 83.22,-415.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"85.91,-417.7 90.68,-408.24 81.05,-412.65 85.91,-417.7\"/>\n",
       "</g>\n",
       "<!-- 140635893098752 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140635893098752</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"72.24,-526 18.24,-526 18.24,-498 72.24,-498 72.24,-526\"/>\n",
       "<text text-anchor=\"middle\" x=\"45.24\" y=\"-514\" font-family=\"monospace\" font-size=\"10.00\">z1</text>\n",
       "<text text-anchor=\"middle\" x=\"45.24\" y=\"-504\" font-family=\"monospace\" font-size=\"10.00\"> (4, 3)</text>\n",
       "</g>\n",
       "<!-- 140635893098752&#45;&gt;140635892682656 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140635893098752&#45;&gt;140635892682656</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M45.24,-497.78C45.24,-490.18 45.24,-480.53 45.24,-472.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"48.74,-472.05 45.24,-462.05 41.74,-472.05 48.74,-472.05\"/>\n",
       "</g>\n",
       "<!-- 140635892682416 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140635892682416</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"198.72,-462 107.76,-462 107.76,-444 198.72,-444 198.72,-462\"/>\n",
       "<text text-anchor=\"middle\" x=\"153.24\" y=\"-450\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140635892682416&#45;&gt;140635892681552 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140635892682416&#45;&gt;140635892681552</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M144.8,-443.88C136.92,-436.29 124.96,-424.76 115.26,-415.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"117.43,-412.65 107.8,-408.24 112.57,-417.7 117.43,-412.65\"/>\n",
       "</g>\n",
       "<!-- 140635894507136 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140635894507136</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"180.24,-526 126.24,-526 126.24,-498 180.24,-498 180.24,-526\"/>\n",
       "<text text-anchor=\"middle\" x=\"153.24\" y=\"-514\" font-family=\"monospace\" font-size=\"10.00\">z2</text>\n",
       "<text text-anchor=\"middle\" x=\"153.24\" y=\"-504\" font-family=\"monospace\" font-size=\"10.00\"> (1, 3)</text>\n",
       "</g>\n",
       "<!-- 140635894507136&#45;&gt;140635892682416 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140635894507136&#45;&gt;140635892682416</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M153.24,-497.78C153.24,-490.18 153.24,-480.53 153.24,-472.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"156.74,-472.05 153.24,-462.05 149.74,-472.05 156.74,-472.05\"/>\n",
       "</g>\n",
       "<!-- 140635892680544&#45;&gt;140635892680496 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140635892680544&#45;&gt;140635892680496</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M128.77,-335.88C123.87,-328.59 116.52,-317.68 110.39,-308.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"113.27,-306.58 104.78,-300.24 107.46,-310.49 113.27,-306.58\"/>\n",
       "</g>\n",
       "<!-- 140635892679488&#45;&gt;140635892680688 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>140635892679488&#45;&gt;140635892680688</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M129.61,-173.88C124.57,-166.59 117.02,-155.68 110.7,-146.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"113.51,-144.47 104.94,-138.24 107.76,-148.45 113.51,-144.47\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fe8586d0280>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchviz\n",
    "torchviz.make_dot(L, params=dict(z1=z1, z2=z2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The next ingredient of the solution is the cross-entropy loss function.\n",
    "\n",
    "Recall that we need to encode our ground-truth labels as one-hot vectors to apply the multiclass cross-entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.191534Z",
     "iopub.status.busy": "2022-03-31T05:57:24.191440Z",
     "iopub.status.idle": "2022-03-31T05:57:24.216881Z",
     "shell.execute_reply": "2022-03-31T05:57:24.216509Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y: Tensor, y_hat: Tensor, eps=1e-6):\n",
    "    \"\"\"\n",
    "    :param y:  Onehot-encoded ground-truth labels, shape (N, C)\n",
    "    :param y_hat: A batch of probabilities, shape (N,C)\n",
    "    :returns: Cross entropy between y and y_hat.\n",
    "    \"\"\"\n",
    "    return torch.sum( - y * torch.log(y_hat + eps) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.218798Z",
     "iopub.status.busy": "2022-03-31T05:57:24.218696Z",
     "iopub.status.idle": "2022-03-31T05:57:24.239370Z",
     "shell.execute_reply": "2022-03-31T05:57:24.239057Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def onehot(y: Tensor, n_classes: int) -> Tensor:\n",
    "    \"\"\"\n",
    "    Encodes y of shape (N,) containing class labels in the range [0,C-1] as one-hot of shape (N,C).\n",
    "    \"\"\"\n",
    "    y = y.reshape(-1, 1) # Reshape y to (N,1)\n",
    "    zeros = torch.zeros(size=(len(y), n_classes), dtype=torch.float32) # (N,C)\n",
    "    ones = torch.ones_like(y, dtype=torch.float32)\n",
    "    \n",
    "    # scatter: put items from 'src' into 'dest' at indices correspondnig to 'index' along 'dim'\n",
    "    y_onehot = torch.scatter(zeros, dim=1, index=y, src=ones)\n",
    "    \n",
    "    return y_onehot # result has shape (N, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.241335Z",
     "iopub.status.busy": "2022-03-31T05:57:24.241127Z",
     "iopub.status.idle": "2022-03-31T05:57:24.264310Z",
     "shell.execute_reply": "2022-03-31T05:57:24.264005Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot(torch.tensor([1, 3, 5, 0]), n_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Our model itself will just hold the parameters $\\mat{W}$ and $\\vec{b}$ and apply them to an input batch $\\mat{X}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.266157Z",
     "iopub.status.busy": "2022-03-31T05:57:24.266051Z",
     "iopub.status.idle": "2022-03-31T05:57:24.287258Z",
     "shell.execute_reply": "2022-03-31T05:57:24.286921Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class MCLogisticRegression(object):\n",
    "    def __init__(self, n_features: int, n_classes: int):\n",
    "        # Define our parameter tensors: notice that now W and b are separate\n",
    "        # Specify we want to track their gradients with autograd\n",
    "        self.W = torch.randn(n_features, n_classes, requires_grad=True)\n",
    "        self.b = torch.randn(n_classes, requires_grad=True)\n",
    "        self.params = [self.W, self.b]\n",
    "    \n",
    "    def __call__(self, *args):\n",
    "        return self.forward(*args)\n",
    "\n",
    "    def forward(self, X: Tensor):\n",
    "        \"\"\"\n",
    "        :param X: A batch of samples, (N, D)\n",
    "        :return: A batch of class probabilities, (N, C)\n",
    "        \"\"\"\n",
    "        # X is (N, D), W is (D, C), b is (C,)\n",
    "        z = torch.mm(X, self.W) + self.b\n",
    "        y_hat = softmax(z)\n",
    "        return y_hat # (N, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's try out the model and loss on the first batch.\n",
    "\n",
    "Note that we navely treat each pixel as a separate feature. We'll learn how to properly work with images in a future tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.289076Z",
     "iopub.status.busy": "2022-03-31T05:57:24.288990Z",
     "iopub.status.idle": "2022-03-31T05:57:24.309803Z",
     "shell.execute_reply": "2022-03-31T05:57:24.309511Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x0_flat: torch.Size([64, 784])\n",
      "y0_onehot: torch.Size([64, 10])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MCLogisticRegression(n_features, n_classes)\n",
    "\n",
    "# Flatten images and convert labels to onehot\n",
    "x0_flat = x0.reshape(-1, n_features)\n",
    "y0_onehot =  onehot(y0, n_classes)\n",
    "\n",
    "print(f'x0_flat: {x0_flat.shape}')\n",
    "print(f'y0_onehot: {y0_onehot.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.311535Z",
     "iopub.status.busy": "2022-03-31T05:57:24.311432Z",
     "iopub.status.idle": "2022-03-31T05:57:24.341704Z",
     "shell.execute_reply": "2022-03-31T05:57:24.341414Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss =  tensor(611.5060, grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Forward pass and compute loss\n",
    "y0_hat = model(x0_flat)\n",
    "loss = cross_entropy_loss(y0_onehot, y0_hat)\n",
    "print('loss = ', loss)\n",
    "\n",
    "# Backward pass to populate .grad on leaf nodes\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Since we specified `require_grad=True` for our model parameters, every operation performed on these tensors is recorded, and a **computation graph** can be built, which included the model and loss calculation.\n",
    "Notice that the **leaves** in this graph are our parameters $\\mat{W}$ and $\\vec{b}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.343575Z",
     "iopub.status.busy": "2022-03-31T05:57:24.343462Z",
     "iopub.status.idle": "2022-03-31T05:57:24.403420Z",
     "shell.execute_reply": "2022-03-31T05:57:24.403037Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.42.3 (20191010.1750)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"202pt\" height=\"760pt\"\n",
       " viewBox=\"0.00 0.00 202.48 760.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 756)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-756 198.48,-756 198.48,4 -4,4\"/>\n",
       "<!-- 140635892802720 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140635892802720</title>\n",
       "<polygon fill=\"#caff70\" stroke=\"black\" points=\"124.24,-30 70.24,-30 70.24,0 124.24,0 124.24,-30\"/>\n",
       "<text text-anchor=\"middle\" x=\"97.24\" y=\"-6\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n",
       "</g>\n",
       "<!-- 140635227845392 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140635227845392</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"140.27,-84 54.21,-84 54.21,-66 140.27,-66 140.27,-84\"/>\n",
       "<text text-anchor=\"middle\" x=\"97.24\" y=\"-72\" font-family=\"monospace\" font-size=\"10.00\">SumBackward0</text>\n",
       "</g>\n",
       "<!-- 140635227845392&#45;&gt;140635892802720 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>140635227845392&#45;&gt;140635892802720</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97.24,-65.94C97.24,-59.31 97.24,-49.57 97.24,-40.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.74,-40.24 97.24,-30.24 93.74,-40.24 100.74,-40.24\"/>\n",
       "</g>\n",
       "<!-- 140635227848080 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140635227848080</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"137.82,-138 56.66,-138 56.66,-120 137.82,-120 137.82,-138\"/>\n",
       "<text text-anchor=\"middle\" x=\"97.24\" y=\"-126\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n",
       "</g>\n",
       "<!-- 140635227848080&#45;&gt;140635227845392 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140635227848080&#45;&gt;140635227845392</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97.24,-119.88C97.24,-113.05 97.24,-103.03 97.24,-94.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.74,-94.24 97.24,-84.24 93.74,-94.24 100.74,-94.24\"/>\n",
       "</g>\n",
       "<!-- 140635228116640 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>140635228116640</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"138.39,-192 56.09,-192 56.09,-174 138.39,-174 138.39,-192\"/>\n",
       "<text text-anchor=\"middle\" x=\"97.24\" y=\"-180\" font-family=\"monospace\" font-size=\"10.00\">LogBackward0</text>\n",
       "</g>\n",
       "<!-- 140635228116640&#45;&gt;140635227848080 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140635228116640&#45;&gt;140635227848080</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97.24,-173.88C97.24,-167.05 97.24,-157.03 97.24,-148.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.74,-148.24 97.24,-138.24 93.74,-148.24 100.74,-148.24\"/>\n",
       "</g>\n",
       "<!-- 140635228116304 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>140635228116304</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"139,-246 55.48,-246 55.48,-228 139,-228 139,-246\"/>\n",
       "<text text-anchor=\"middle\" x=\"97.24\" y=\"-234\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140635228116304&#45;&gt;140635228116640 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>140635228116304&#45;&gt;140635228116640</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97.24,-227.88C97.24,-221.05 97.24,-211.03 97.24,-202.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.74,-202.24 97.24,-192.24 93.74,-202.24 100.74,-202.24\"/>\n",
       "</g>\n",
       "<!-- 140635228116880 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>140635228116880</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"137.15,-300 57.33,-300 57.33,-282 137.15,-282 137.15,-300\"/>\n",
       "<text text-anchor=\"middle\" x=\"97.24\" y=\"-288\" font-family=\"monospace\" font-size=\"10.00\">DivBackward0</text>\n",
       "</g>\n",
       "<!-- 140635228116880&#45;&gt;140635228116304 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>140635228116880&#45;&gt;140635228116304</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97.24,-281.88C97.24,-275.05 97.24,-265.03 97.24,-256.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.74,-256.24 97.24,-246.24 93.74,-256.24 100.74,-256.24\"/>\n",
       "</g>\n",
       "<!-- 140635228115584 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>140635228115584</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"138.44,-408 56.04,-408 56.04,-390 138.44,-390 138.44,-408\"/>\n",
       "<text text-anchor=\"middle\" x=\"97.24\" y=\"-396\" font-family=\"monospace\" font-size=\"10.00\">ExpBackward0</text>\n",
       "</g>\n",
       "<!-- 140635228115584&#45;&gt;140635228116880 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>140635228115584&#45;&gt;140635228116880</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M93.28,-389.8C89.32,-381.14 83.52,-366.97 81.24,-354 78.56,-338.78 83.51,-321.8 88.59,-309.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"91.79,-310.89 92.73,-300.33 85.42,-308 91.79,-310.89\"/>\n",
       "</g>\n",
       "<!-- 140635228118752 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>140635228118752</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"176.27,-354 90.21,-354 90.21,-336 176.27,-336 176.27,-354\"/>\n",
       "<text text-anchor=\"middle\" x=\"133.24\" y=\"-342\" font-family=\"monospace\" font-size=\"10.00\">SumBackward1</text>\n",
       "</g>\n",
       "<!-- 140635228115584&#45;&gt;140635228118752 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>140635228115584&#45;&gt;140635228118752</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M102.86,-389.88C107.91,-382.59 115.46,-371.68 121.77,-362.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"124.72,-364.45 127.53,-354.24 118.96,-360.47 124.72,-364.45\"/>\n",
       "</g>\n",
       "<!-- 140635228115536 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>140635228115536</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"139,-462 55.48,-462 55.48,-444 139,-444 139,-462\"/>\n",
       "<text text-anchor=\"middle\" x=\"97.24\" y=\"-450\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n",
       "</g>\n",
       "<!-- 140635228115536&#45;&gt;140635228115584 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>140635228115536&#45;&gt;140635228115584</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M97.24,-443.88C97.24,-437.05 97.24,-427.03 97.24,-418.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"100.74,-418.24 97.24,-408.24 93.74,-418.24 100.74,-418.24\"/>\n",
       "</g>\n",
       "<!-- 140635228115776 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>140635228115776</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"139,-570 55.48,-570 55.48,-552 139,-552 139,-570\"/>\n",
       "<text text-anchor=\"middle\" x=\"97.24\" y=\"-558\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n",
       "</g>\n",
       "<!-- 140635228115776&#45;&gt;140635228115536 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>140635228115776&#45;&gt;140635228115536</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M93.28,-551.8C89.32,-543.14 83.52,-528.97 81.24,-516 78.56,-500.78 83.51,-483.8 88.59,-471.46\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"91.79,-472.89 92.73,-462.33 85.42,-470 91.79,-472.89\"/>\n",
       "</g>\n",
       "<!-- 140635228116208 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>140635228116208</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"174.6,-516 89.88,-516 89.88,-498 174.6,-498 174.6,-516\"/>\n",
       "<text text-anchor=\"middle\" x=\"132.24\" y=\"-504\" font-family=\"monospace\" font-size=\"10.00\">MaxBackward0</text>\n",
       "</g>\n",
       "<!-- 140635228115776&#45;&gt;140635228116208 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>140635228115776&#45;&gt;140635228116208</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M102.71,-551.88C107.61,-544.59 114.95,-533.68 121.09,-524.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"124.01,-526.49 126.69,-516.24 118.21,-522.58 124.01,-526.49\"/>\n",
       "</g>\n",
       "<!-- 140635228118320 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>140635228118320</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"86.37,-624 4.11,-624 4.11,-606 86.37,-606 86.37,-624\"/>\n",
       "<text text-anchor=\"middle\" x=\"45.24\" y=\"-612\" font-family=\"monospace\" font-size=\"10.00\">MmBackward0</text>\n",
       "</g>\n",
       "<!-- 140635228118320&#45;&gt;140635228115776 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>140635228118320&#45;&gt;140635228115776</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M53.36,-605.88C60.95,-598.29 72.47,-586.76 81.81,-577.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.4,-579.79 89,-570.24 79.45,-574.84 84.4,-579.79\"/>\n",
       "</g>\n",
       "<!-- 140635228115008 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>140635228115008</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"90.72,-683 -0.24,-683 -0.24,-665 90.72,-665 90.72,-683\"/>\n",
       "<text text-anchor=\"middle\" x=\"45.24\" y=\"-671\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140635228115008&#45;&gt;140635228118320 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>140635228115008&#45;&gt;140635228118320</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M45.24,-664.59C45.24,-656.67 45.24,-644.54 45.24,-634.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"48.74,-634.08 45.24,-624.08 41.74,-634.08 48.74,-634.08\"/>\n",
       "</g>\n",
       "<!-- 140635694856368 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>140635694856368</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"74.54,-752 15.94,-752 15.94,-724 74.54,-724 74.54,-752\"/>\n",
       "<text text-anchor=\"middle\" x=\"45.24\" y=\"-740\" font-family=\"monospace\" font-size=\"10.00\">W</text>\n",
       "<text text-anchor=\"middle\" x=\"45.24\" y=\"-730\" font-family=\"monospace\" font-size=\"10.00\"> (784, 10)</text>\n",
       "</g>\n",
       "<!-- 140635694856368&#45;&gt;140635228115008 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>140635694856368&#45;&gt;140635228115008</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M45.24,-723.85C45.24,-714.96 45.24,-703.1 45.24,-693.29\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"48.74,-693.02 45.24,-683.02 41.74,-693.02 48.74,-693.02\"/>\n",
       "</g>\n",
       "<!-- 140635228115248 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>140635228115248</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"194.72,-624 103.76,-624 103.76,-606 194.72,-606 194.72,-624\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.24\" y=\"-612\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n",
       "</g>\n",
       "<!-- 140635228115248&#45;&gt;140635228115776 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>140635228115248&#45;&gt;140635228115776</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M141.11,-605.88C133.53,-598.29 122,-586.76 112.67,-577.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"115.02,-574.84 105.48,-570.24 110.07,-579.79 115.02,-574.84\"/>\n",
       "</g>\n",
       "<!-- 140635892802080 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>140635892802080</title>\n",
       "<polygon fill=\"lightblue\" stroke=\"black\" points=\"176.24,-688 122.24,-688 122.24,-660 176.24,-660 176.24,-688\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.24\" y=\"-676\" font-family=\"monospace\" font-size=\"10.00\">b</text>\n",
       "<text text-anchor=\"middle\" x=\"149.24\" y=\"-666\" font-family=\"monospace\" font-size=\"10.00\"> (10)</text>\n",
       "</g>\n",
       "<!-- 140635892802080&#45;&gt;140635228115248 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>140635892802080&#45;&gt;140635228115248</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M149.24,-659.78C149.24,-652.18 149.24,-642.53 149.24,-634.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"152.74,-634.05 149.24,-624.05 145.74,-634.05 152.74,-634.05\"/>\n",
       "</g>\n",
       "<!-- 140635228116208&#45;&gt;140635228115536 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>140635228116208&#45;&gt;140635228115536</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M126.77,-497.88C121.87,-490.59 114.52,-479.68 108.39,-470.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"111.27,-468.58 102.78,-462.24 105.46,-472.49 111.27,-468.58\"/>\n",
       "</g>\n",
       "<!-- 140635228118752&#45;&gt;140635228116880 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>140635228118752&#45;&gt;140635228116880</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M127.61,-335.88C122.57,-328.59 115.02,-317.68 108.7,-308.56\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"111.51,-306.47 102.94,-300.24 105.76,-310.45 111.51,-306.47\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fe830cc7a90>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchviz\n",
    "torchviz.make_dot(loss, params=dict(W=model.W, b=model.b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This graph is what allows efficient implementation of the **back-propagation** algorithm which you'll learn about in the next lecture.\n",
    "\n",
    "By calling `.backward()` from the final loss tensor, pytorch automatically populated the `.grad` property of all leaves in this graph, without us having to explicitly specify them (`W` and `b`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The optimization will be as before, but now we'll take the gradients from the `grad` property of our parameter tensors.\n",
    "\n",
    "Therefore, the optimizer only needs access to the parameter tensors from the model.\n",
    "Later you'll see that `pytorch`'s `Optimizer` classes work in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.405910Z",
     "iopub.status.busy": "2022-03-31T05:57:24.405767Z",
     "iopub.status.idle": "2022-03-31T05:57:24.434454Z",
     "shell.execute_reply": "2022-03-31T05:57:24.434135Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "class SGDOptimizer:\n",
    "    \"\"\"\n",
    "    A simple gradient descent optimizer.\n",
    "    \"\"\"\n",
    "    def __init__(self, params: Sequence[Tensor], learn_rate: float):\n",
    "        self._params = params\n",
    "        self._learn_rate = learn_rate\n",
    "    \n",
    "    def step(self):\n",
    "        \"\"\"\n",
    "        Updates parameters in-place based on their gradients.\n",
    "        \"\"\"\n",
    "        with torch.autograd.no_grad(): # Don't track this operation\n",
    "            for param in self._params:\n",
    "                if param.grad is not None:\n",
    "                    param -= self._learn_rate * param.grad\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        \"\"\"\n",
    "        Zeros the parameters' gradients if they exist.\n",
    "        \"\"\"\n",
    "        for param in self._params:\n",
    "            if param.grad is not None:\n",
    "                param.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Inference and prediction accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.436398Z",
     "iopub.status.busy": "2022-03-31T05:57:24.436289Z",
     "iopub.status.idle": "2022-03-31T05:57:24.865375Z",
     "shell.execute_reply": "2022-03-31T05:57:24.865010Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy pre-training: 7.65%\n"
     ]
    }
   ],
   "source": [
    "def evaluate_accuracy(dataloader, model, max_batches=None):\n",
    "    n_correct = 0.\n",
    "    n_total = 0.\n",
    "    for i, (X, y) in enumerate(dataloader):\n",
    "        X = X.reshape(-1, n_features) # flatten images into vectors\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.autograd.no_grad():\n",
    "            y_hat = model(X)\n",
    "        \n",
    "        predictions = torch.argmax(y_hat, dim=1)\n",
    "        n_correct += torch.sum(predictions == y).type(torch.float32)\n",
    "        n_total += X.shape[0]\n",
    "        \n",
    "        if max_batches and i+1 >= max_batches:\n",
    "            break\n",
    "        \n",
    "    return (n_correct / n_total).item()\n",
    "\n",
    "test_set_acc = evaluate_accuracy(dl_test, MCLogisticRegression(n_features, n_classes))\n",
    "print(f'Test set accuracy pre-training: {test_set_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### The training loop\n",
    "\n",
    "This is a crucial part of any ML pipeline where model parameters get updated iteratively.\n",
    "\n",
    "One pass over the entire training data is called an **epoch**.\n",
    "When using `pytorch`, your training loop will generally contain the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Each epoch:\n",
    "    - Split training data into batches\n",
    "    - For each batch\n",
    "        - Forward pass: Compute predictions and build computation graph\n",
    "        - Calculate loss\n",
    "        - Set existing gradients to zero\n",
    "        - Backward pass: Use back-propagation algorithm to calculate the gradients\n",
    "        - Optimization step: Use the gradients to update the parameters\n",
    "    - Evaluate accuracy on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.867454Z",
     "iopub.status.busy": "2022-03-31T05:57:24.867240Z",
     "iopub.status.idle": "2022-03-31T05:57:24.889412Z",
     "shell.execute_reply": "2022-03-31T05:57:24.889080Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Define some training hyper-parameters\n",
    "epochs = 10\n",
    "max_batches = 50  # limit batches so training is fast (just as a demo)\n",
    "learn_rate = .005\n",
    "num_samples = len(ds_train)\n",
    "\n",
    "# Instantiate the model we'll train\n",
    "model = MCLogisticRegression(n_features, n_classes)\n",
    "\n",
    "# Instantiate the optimizer with model's parameters\n",
    "optimizer = SGDOptimizer(model.params, learn_rate=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T05:57:24.891427Z",
     "iopub.status.busy": "2022-03-31T05:57:24.891315Z",
     "iopub.status.idle": "2022-03-31T05:57:32.282770Z",
     "shell.execute_reply": "2022-03-31T05:57:32.282443Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Avg Loss: 0.352, Train Acc: 41.69, Test Acc: 43.67\n",
      "Epoch 1. Avg Loss: 0.161, Train Acc: 63.34, Test Acc: 63.29\n",
      "Epoch 2. Avg Loss: 0.099, Train Acc: 70.88, Test Acc: 71.77\n",
      "Epoch 3. Avg Loss: 0.075, Train Acc: 74.84, Test Acc: 76.31\n",
      "Epoch 4. Avg Loss: 0.064, Train Acc: 78.12, Test Acc: 78.12\n",
      "Epoch 5. Avg Loss: 0.058, Train Acc: 79.03, Test Acc: 79.77\n",
      "Epoch 6. Avg Loss: 0.053, Train Acc: 80.03, Test Acc: 81.39\n",
      "Epoch 7. Avg Loss: 0.050, Train Acc: 80.84, Test Acc: 82.08\n",
      "Epoch 8. Avg Loss: 0.051, Train Acc: 81.88, Test Acc: 83.58\n",
      "Epoch 9. Avg Loss: 0.047, Train Acc: 83.00, Test Acc: 83.77\n"
     ]
    }
   ],
   "source": [
    "# Epoch: traverse all samples\n",
    "for e in range(epochs):\n",
    "    cumulative_loss = 0\n",
    "\n",
    "    # Loop over randdom batches of training data\n",
    "    for i, (X, y) in enumerate(dl_train):\n",
    "        \n",
    "        X = X.reshape(-1, n_features)\n",
    "        y_onehot = onehot(y, n_classes)\n",
    "        \n",
    "        # Forward pass: predictions and loss\n",
    "        y_hat = model(X)\n",
    "        loss = cross_entropy_loss(y_onehot, y_hat)\n",
    "        \n",
    "        # Clear previous gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Backward pass: calculate gradients \n",
    "        loss.backward() \n",
    "        \n",
    "        # Update model using the calculated gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        cumulative_loss += loss.item()\n",
    "        if i+1 > max_batches:\n",
    "            break\n",
    "\n",
    "    # Evaluation\n",
    "    test_accuracy = evaluate_accuracy(dl_test, model, max_batches)\n",
    "    train_accuracy = evaluate_accuracy(dl_train, model, max_batches)\n",
    "    \n",
    "    avg_loss = cumulative_loss/num_samples\n",
    "    print(f\"Epoch {e}. Avg Loss: {avg_loss:.3f}, Train Acc: {train_accuracy*100:.2f}, Test Acc: {test_accuracy*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Final notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- This is a very naive implementation, for example because\n",
    "    - We didn't treat the images properly.\n",
    "    - We didn't include any regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- PyTorch provides many functions and classes that we could have used, for example:\n",
    "  - Fully connected layer with model parameters\n",
    "  - Softmax\n",
    "  - SGD and many other optimizers\n",
    "  - Cross entropy loss\n",
    "  \n",
    "  however the purpose here was to show an (almost) from-scratch implementation using only tensors,\n",
    "  in order to see whats \"under the hood\" (more or less) of the PyTorch functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Thanks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Credits**\n",
    "\n",
    "This tutorial was written by [Aviv A. Rosenberg](https://avivr.net).<br>\n",
    "To re-use, please provide attribution and link to the original.\n",
    "\n",
    "Some images in this tutorial were taken and/or adapted from the following sources:\n",
    "\n",
    "- MartinThoma [CC0], via Wikimedia Commons https://commons.wikimedia.org/wiki/File:Perceptron-unit.svg\n",
    "- Dr. Nadav Cohen, http://www.cohennadav.com/files/icermw19_slides.pdf\n",
    "- Fundamentals of Deep Learning, Nikhil Buduma, Oreilly 2017"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
